<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Hongxu Xu</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->
        <!-- Google tag (gtag.js) -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-PMJ5E1FYG6"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
        
          gtag('config', 'G-PMJ5E1FYG6');
        </script>
        <meta name="description" content="Hongxu Xu&#x27;s personal website">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">
        <meta property="og:title" content="print.md" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="style.css">

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Hongxu Xu</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="hongxu-xu"><a class="header" href="#hongxu-xu">Hongxu Xu</a></h1>
<img class="right circle" src="https://avatars.githubusercontent.com/u/2201482?v=4" alt="Hongxu Xu" width="160px">
<p><strong>PhD Student (May 2025 – Present)</strong><br />
Supervised by <a href="https://cs.uwaterloo.ca/~cnsun">Prof. Chengnian Sun</a><br />
<a href="https://cs.uwaterloo.ca/">Cheriton School of Computer Science</a><br />
<a href="https://uwaterloo.ca/">University of Waterloo</a>, Canada</p>
<p><strong>B.Sc. in Computer Science (Sep 2014 – Jun 2018)</strong><br />
<a href="https://www.bnu.edu.cn/">Beijing Normal University</a>, China</p>
<h2 id="research-interests"><a class="header" href="#research-interests">Research Interests</a></h2>
<ul>
<li>Software Engineering</li>
<li>Programming Languages</li>
</ul>
<p>without a focus yet…</p>
<h2 id="socials"><a class="header" href="#socials">Socials</a></h2>
<img class="right" src="wechat_mp.jpg" alt="WeChat MP" width="160px">
<ul>
<li>GitHub: <a href="https://github.com/xuhongxu96">https://github.com/xuhongxu96</a></li>
<li>LinkedIn: <a href="https://www.linkedin.com/in/xuhongxu/">https://www.linkedin.com/in/xuhongxu/</a></li>
<li>Email: h4️⃣4️⃣5️⃣xu 🌀 uwaterloo.ca</li>
<li>微信公众号: xuhongxu_it<br />
(<strong>Chinese only</strong>. <em>Scan the QR code to follow my WeChat Official Account</em>.)</li>
</ul>
<h2 id="misc"><a class="header" href="#misc">Misc.</a></h2>
<ul>
<li>Chinese Name: 许宏旭</li>
<li>Pronunciation: <code>Hong-shyoo</code> (IPA: <code>[xʊŋ ɕy]</code>)</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="publications"><a class="header" href="#publications">Publications</a></h1>
<h2 id="papers"><a class="header" href="#papers">Papers</a></h2>
<p>Nothing yet…</p>
<h2 id="books"><a class="header" href="#books">Books</a></h2>
<ul>
<li><code>Feb 2024</code> <a href="https://book.douban.com/subject/36787652/">CMake构建实战：项目开发卷 (CMake Build Practice: Project Development Volume)</a><br />
Published by <a href="https://www.ptpress.com.cn/">人民邮电出版社 (Posts &amp; Telecom Press, China)</a><br />
Produced by <a href="https://www.epubit.com/">异步图书 (epubit)</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="experience"><a class="header" href="#experience">Experience</a></h1>
<h2 id="phd-student-may-2025--present"><a class="header" href="#phd-student-may-2025--present">PhD Student (May 2025 – Present)</a></h2>
<p>Supervised by <a href="https://cs.uwaterloo.ca/~cnsun">Prof. Chengnian Sun</a></p>
<p><a href="https://cs.uwaterloo.ca/">Cheriton School of Computer Science</a><br />
<a href="https://uwaterloo.ca/">University of Waterloo</a>, Canada</p>
<h2 id="senior-sde-sep-2022--mar-2025"><a class="header" href="#senior-sde-sep-2022--mar-2025">Senior SDE (Sep 2022 – Mar 2025)</a></h2>
<p><a href="https://seed.bytedance.com/en/direction/speech">Seed/Data Speech Team</a><br />
<a href="https://www.bytedance.com/en/">ByteDance</a>, Shanghai, China</p>
<p><em>Led the development of the Text-to-Speech engine and contributed to the Doubao AI assistant application.</em></p>
<!-- - Led the architectural design and development of the Text-to-Speech
  front-end engine, overseeing its overall system integration.
- Developed a streaming Markdown parser, based on the cmark open-source
  library, capable of real-time, character-wise parsing of Markdown
  generated by large language models. Authored a patent for this work,
  which has been adopted in the Doubao/Cici AI assistant application.
- Designed and implemented a cross-lingual [SSML](https://www.w3.org/TR/speech-synthesis11/) framework that lowers
  SSML abstract syntax trees to an intermediate representation,
  facilitating flexible modification of synthesized speech across
  multiple languages.
- Enhanced CI/CD pipelines and testing infrastructure by integrating
  sanitizers and static analyzers into continuous integration workflows.
- Collaborated with research teams to engineer and deploy
  state-of-the-art speech AI models based on large language models. -->
<h2 id="sde-2-jan-2021--sep-2022"><a class="header" href="#sde-2-jan-2021--sep-2022">SDE-2 (Jan 2021 – Sep 2022)</a></h2>
<p>MSAI Team<br />
<a href="https://www.microsoft.com/en-us/aprd/aboutus/team-stca">Microsoft STC-Asia</a>, Suzhou, China</p>
<p><em>Led the development of Microsoft WordBreaker and initiated a modern NLP toolkit for Office 365.</em></p>
<!-- - Led the development of Microsoft WordBreaker and initiated a 
  modern workflow-based NLP toolkit for Office 365.
- Enhanced Microsoft 365 Search (serving Outlook, Teams, SharePoint, etc.) 
  in global markets by systematically resolving internationalization issues. -->
<h2 id="sde-jul-2018--aug-2021"><a class="header" href="#sde-jul-2018--aug-2021">SDE (Jul 2018 – Aug 2021)</a></h2>
<p>MSAI Team<br />
<a href="https://www.microsoft.com/en-us/aprd/aboutus/team-stca">Microsoft STC-Asia</a><br />
Beijing, China (Transferred to Suzhou, Jiangsu, China in May 2019)</p>
<p><em>Worked on 20-year-old Microsoft WordBreaker.</em></p>
<!-- - Maintained Microsoft WordBreaker, 
  multilingual text segmentation tool used in Bing and Office,
  which has 20 years of history, 
  and includes source code written in both C++98 and C++17.
- Improved Korean WordBreaker performance by >20% through
  stateless refactoring and replacing regex with an
  automaton-based rule engine. -->
<h3 id="short-term-contributor-nov-2020--jan-2021"><a class="header" href="#short-term-contributor-nov-2020--jan-2021">Short-Term Contributor (Nov 2020 – Jan 2021)</a></h3>
<p>Windows APS Team (work on a secondment)<br />
<a href="https://www.microsoft.com/en-us/aprd/aboutus/team-stca">Microsoft STC-Asia</a>, Suzhou, China</p>
<p><em>Contributed to the formation of the new team, and Windows 11 application development.</em></p>
<!-- - Authored design document templates and established DevOps processes to 
  facilitate the formation of a new team for Windows 11 application 
  development. Led initial review meetings to ensure effective onboarding.
- Contributed to the Microsoft Calculator project by encapsulating the 
  native rational calculation library as a cross-platform C# package.
- Assisted in migrating components of the Calculator application from 
  C++/CX to C# using ANTLR 4, a parser generator. -->
<h2 id="bsc-in-computer-science-sep-2014--jun-2018"><a class="header" href="#bsc-in-computer-science-sep-2014--jun-2018">B.Sc. in Computer Science (Sep 2014 – Jun 2018)</a></h2>
<p><a href="https://www.bnu.edu.cn/">Beijing Normal University</a>, China</p>
<h3 id="sde-intern-jul-2017--dec-2017"><a class="header" href="#sde-intern-jul-2017--dec-2017">SDE Intern (Jul 2017 – Dec 2017)</a></h3>
<p>Bing Search Relevance Team<br />
<a href="https://www.microsoft.com/en-us/aprd/aboutus/team-stca">Microsoft STC-Asia</a>, Beijing, China</p>
<p><em>Answer triggering model development for Bing Search.</em></p>
<!-- - Created a CFG (Context-Free Grammar) parser 
  to reduce the complexity of the rules 
  for answer triggering models used in Bing by
  automaton minimization. 
  Reduced the latency by 20%. -->
<div style="break-before: page; page-break-before: always;"></div><h1 id="awards"><a class="header" href="#awards">Awards</a></h1>
<ul>
<li>Outstanding Graduate, Beijing Normal University, 2018</li>
<li>Top Ten Volunteer, Beijing Normal University, 2015</li>
<li>First Prize, National Olympiad in Informatics in Provinces (NOIP), 2013</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="teaching"><a class="header" href="#teaching">Teaching</a></h1>
<ul>
<li>Instructor Apprentice, <a href="https://student.cs.uwaterloo.ca/~cs246/F25/index.shtml">CS 246 - Object-Oriented Software Development</a>, Fall 2025</li>
<li>Teaching Assistant, <a href="https://student.cs.uwaterloo.ca/~cs246/S25/index.shtml">CS 246 - Object-Oriented Software Development</a>, Spring 2025</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cs-452652-real-time-programming-the-train-course"><a class="header" href="#cs-452652-real-time-programming-the-train-course">CS 452/652: Real-Time Programming (the Train Course)</a></h1>
<blockquote>
<p>Spring 25</p>
</blockquote>
<p>I <em>dropped</em> this course after I learned that it is really <em>time-consuming</em>.</p>
<p>However, before I dropped it, I did some research and found some useful resources,
which I summarized in <a href="https://git.uwaterloo.ca/h445xu/cs652">MarklinSim All-in-One</a> repo.</p>
<p>In short, follow the readme in the repo to set up:</p>
<ol>
<li>MarklinSim (an emulator for the train kit)</li>
<li>QEMU (an emulator for the Raspberry Pi 4B)</li>
<li>Example Image (your real-time system).</li>
</ol>
<p>I believe it will save you a lot of time. Good luck!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cs-480680-introduction-to-machine-learning"><a class="header" href="#cs-480680-introduction-to-machine-learning">CS 480/680: Introduction to Machine Learning</a></h1>
<blockquote>
<p>Spring 25</p>
</blockquote>
<p>This is not a hard course.</p>
<p><a href="notes/final-review.pdf">Download PDF</a></p>
<pre><code class="language-latex">\documentclass{article}
\usepackage{fullpage}
\usepackage{float}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{url, hyperref}
\usepackage{algorithm2e}
\usepackage[margin=0.25in]{geometry}
\usepackage{pgfplots}
\pgfplotsset{width=10cm,compat=1.18}

\usepgfplotslibrary{external}
\tikzexternalize

\lstset{basicstyle=\fontfamily{pcr}\footnotesize}

\graphicspath{./}

\newcommand{\paren}[1]{\left( #1 \right)}
\newcommand{\iprod}[1]{\left\langle #1 \right\rangle}

\newcommand*\MY@rightharpoonupfill@{%
    \arrowfill@\relbar\relbar\rightharpoonup
}
\newcommand*\overrightharpoon{%
    \mathpalette{\overarrow@\MY@rightharpoonupfill@}%
}

\theoremstyle{definition}
\newtheorem{question}{Question}

\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Var}{Var}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
\newcommand{\llnorm}[1]{\left\| #1 \right\|_2}
\newcommand{\mnorm}[1]{\left\| #1 \right\|_1}
\newcommand{\fnorm}[1]{\left\| #1 \right\|_F}

\title{\large CS480/680, Spring 2025\\\huge Review Notes}

\author{Student: Hongxu Xu (h445xu@uwaterloo.ca)}
\date{\today}
\setlength\parindent{0pt}

%\input{preamble}

\begin{document}

\maketitle

\newpage

\part{For Mid-Term}

\section{Perceptron}

\begin{question}[Linear Function]
    \begin{equation}
        \begin{split}
            &amp; \forall \alpha \beta \in \mathbb{R}, \forall \boldsymbol{x}, \boldsymbol{z} \in \mathbb{R}^d, 
            f(\alpha \boldsymbol{x} + \beta \boldsymbol{z}) = \alpha \cdot f(\boldsymbol{X}) + \beta \cdot f(\boldsymbol{z}) \\
            \Longleftrightarrow
            &amp; \exists \boldsymbol{w} \in \mathbb{R}^d, f(\boldsymbol{x}) = \iprod{\boldsymbol{x}, \boldsymbol{w}}
        \end{split}
    \end{equation}

    \textbf{Proof $\Rightarrow$:}
    Let $\boldsymbol{w} \coloneq \left[ f(\boldsymbol{e_1}), \dots, f(\boldsymbol{e_d}) \right]^T$, where
    $\boldsymbol{e_i}$ is the $i$-th coordinate vector.
    \begin{equation}
        \begin{split}
            f(\boldsymbol{x}) &amp; = f( x_1 \boldsymbol{e_1} + \dots + x_d \boldsymbol{e_d} ) \\
            &amp; = x_1 f(\boldsymbol{e_1}) + \dots + x_d f(\boldsymbol{e_d}) \\
            &amp; = \iprod{\boldsymbol{x}, \boldsymbol{w}}
        \end{split}
    \end{equation}

    \textbf{Proof $\Leftarrow$:}
    \begin{equation}
        \begin{split}
            f(\alpha \boldsymbol{x} + \beta \boldsymbol{z}) &amp; = \iprod{\alpha \boldsymbol{x} + \beta \boldsymbol{z}, \boldsymbol{w}} \\
            &amp; = \iprod{\alpha \boldsymbol{x}, \boldsymbol{w}} + \iprod{\beta \boldsymbol{z}, \boldsymbol{w}} \\
            &amp; = \alpha \iprod{\boldsymbol{x}, \boldsymbol{w}} + \beta \iprod{\boldsymbol{z}, \boldsymbol{w}} \\
            &amp; = \alpha f(\boldsymbol{x}) + \beta f(\boldsymbol{z})
        \end{split}
    \end{equation}
\end{question}

\begin{question}[$\boldsymbol{w}$ is Orthogonal to Decision Boundary $H$]
    Any vector on $H$ can be written as $\overrightharpoon{\boldsymbol{x}\boldsymbol{x'}} = \boldsymbol{x'} - \boldsymbol{x}$,
    \begin{equation}
            \iprod{\boldsymbol{x'} - \boldsymbol{x}, \boldsymbol{w}} 
            = \iprod{\boldsymbol{x'}, \boldsymbol{w}} - \iprod{\boldsymbol{x}, \boldsymbol{w}}
            = -b - (-b) = 0
    \end{equation}
\end{question}

\begin{question}[Update Rule for Perceptron]
\begin{equation} \label{perceptron-update-rule}
    \begin{split}
        \boldsymbol{w} \leftarrow \boldsymbol{w} + y_i \boldsymbol{x_i} \\
        b \leftarrow = b + y_i
    \end{split}
\end{equation}
\end{question}

\begin{question}[Feasibility of Perceptron]
The goal is to find $\boldsymbol{w} \in \mathbb{R}^d, b \in \mathbb{R}$, 
such that $\forall i, y_i \paren{\iprod{\boldsymbol{x_i}, \boldsymbol{w}} + b} &gt; 0$.

According to the update rule \ref{perceptron-update-rule},
\begin{equation}
    \begin{split}
        y\left[ \iprod{\boldsymbol{x}, \boldsymbol{w_{new}}} + b_{new} \right]
        &amp;= y\left[ \iprod{\boldsymbol{x}, \boldsymbol{w_{old} + y \boldsymbol{x}}} + b_{old} + y \right] \\
        &amp;= y\left[ \iprod{\boldsymbol{x}, \boldsymbol{w_{old}}} + b_{old} \right] + y\left[ \iprod{\boldsymbol{x} ,y \boldsymbol{x}} + y \right] \\
        &amp;= y\left[ \iprod{\boldsymbol{x}, \boldsymbol{w_{old}}} + b_{old} \right] + y\left[ y \llnorm{\boldsymbol{x}}^2 + y \right] \\
        &amp;= y\left[ \iprod{\boldsymbol{x}, \boldsymbol{w_{old}}} + b_{old} \right] + y^2 \llnorm{\boldsymbol{x}}^2 + y^2 \\
        &amp;= y\left[ \iprod{\boldsymbol{x}, \boldsymbol{w_{old}}} + b_{old} \right] + \underbrace{\llnorm{\boldsymbol{x}}^2 + 1}_{\text{always positive}}
    \end{split}
\end{equation}
Notice that $y \in \left\{ \pm 1 \right\} \Rightarrow y^2 = 1$.

$\llnorm{\boldsymbol{x}}^2 + 1$ is always positive, which means we always increase the confidence $y \hat{y}$ after the update.
\end{question}

\begin{question}[Trick for Hiding the Bias Term -- Padding]
    \begin{equation}
        \begin{split}
            \iprod{\boldsymbol{x}, \boldsymbol{w}} + b 
            &amp; = \iprod{ \begin{pmatrix} \boldsymbol{x} \\ 1 \end{pmatrix}, \begin{pmatrix} \boldsymbol{w} \\ b \end{pmatrix} } \\
            &amp; = \iprod{ \boldsymbol{x_{pad}}, \boldsymbol{w_{pad}}}
        \end{split}
    \end{equation}
    Correspondingly, the update rule can be written as:
    \begin{equation}
        \boldsymbol{w_{pad}} \leftarrow \boldsymbol{w_{pad}} + y \boldsymbol{x_{pad}}
    \end{equation}
\end{question}

\begin{question}[Margin]
    Suppose $\exists \boldsymbol{w^*}$ such that $\forall i, y_i \iprod{\boldsymbol{x_i}, \boldsymbol{w^*}} &gt; 0$.

    We normalize $\boldsymbol{w^*}$ such that $\llnorm{\boldsymbol{w^*}} = 1$.

    In other words, $\boldsymbol{w^*}$ is the normalized weight for the deicision boundary.

    \begin{equation} \label{margin}
        \text{Margin } \gamma \coloneq \min_i \left| \iprod{\boldsymbol{x_i}, \boldsymbol{w^*}} \right|
    \end{equation}
\end{question}

\begin{question}[Convergence Theorem -- Linearly Separable Case]
    Assume that $\forall i, \llnorm{\boldsymbol{x_i}} \leq C$ (i.e. within a circle with radius $C$).

    Then the Perceptron algorithm converges after $\frac{C^2}{\gamma^2}$ mistakes.

    \vspace{5mm}
    \textbf{Proof:}

    Suppose $\boldsymbol{w}$ is the updating weight, and $\theta$ is the angle between $\boldsymbol{w}$ and $\boldsymbol{w^*}$. 

    We have $\iprod{\boldsymbol{w}, \boldsymbol{w^*}} = \llnorm{\boldsymbol{w}} \llnorm{\boldsymbol{w^*}} \cos{\theta} = \llnorm{\boldsymbol{w}} \cos{\theta}$.
    
    After an update, $\llnorm{\boldsymbol{w_{new}}} \cos{\theta_{new}}$ will be
    \begin{equation}
        \begin{split}
            \iprod{\boldsymbol{w} + y \boldsymbol{x}, \boldsymbol{w^*}}
            &amp; = \iprod{\boldsymbol{w}, \boldsymbol{w^*}} + y \iprod{\boldsymbol{x}, \boldsymbol{w^*}} \\
            &amp; = \iprod{\boldsymbol{w}, \boldsymbol{w^*}} + \left|\iprod{\boldsymbol{x}, \boldsymbol{w^*}}\right| \\
            &amp; \geq \iprod{\boldsymbol{w}, \boldsymbol{w^*}} + \gamma
        \end{split}
    \end{equation}

    Let's see the change of $\iprod{\boldsymbol{w_{new}}, \boldsymbol{w_{new}}} = \llnorm{\boldsymbol{w_{new}}}^2$,
    \begin{equation}
        \begin{split}
            \iprod{\boldsymbol{w} + y \boldsymbol{x}, \boldsymbol{w} + y \boldsymbol{x}}
            &amp; = \iprod{\boldsymbol{w}, \boldsymbol{w}} + 2y \iprod{\boldsymbol{w}, \boldsymbol{x}} + y^2 \iprod{\boldsymbol{x}, \boldsymbol{x}} \\
            &amp; = \llnorm{\boldsymbol{w}}^2 + 2y \iprod{\boldsymbol{w}, \boldsymbol{x}} + \llnorm{\boldsymbol{x}}^2
        \end{split}
    \end{equation}
    Because $y\iprod{\boldsymbol{w}, \boldsymbol{x}} &lt; 0$ and $\llnorm{\boldsymbol{x}} \leq C$,
    \begin{equation}
        \begin{split}
            \iprod{\boldsymbol{w} + y \boldsymbol{x}, \boldsymbol{w} + y \boldsymbol{x}}
            &amp; = \llnorm{\boldsymbol{w}}^2 + 2y \iprod{\boldsymbol{w}, \boldsymbol{x}} + \llnorm{\boldsymbol{x}}^2 \\
            &amp; \leq \llnorm{\boldsymbol{w}}^2 + C^2
        \end{split}
    \end{equation}

    Finally, suppose it converges after $M$ updates, we have $\iprod{\boldsymbol{w}, \boldsymbol{w^*}} \geq M \gamma$ and $\llnorm{\boldsymbol{w}}^2 \leq M C^2$
    \begin{equation}
        \begin{split}
            1 = \cos{\theta} &amp; = \frac{\iprod{\boldsymbol{w}, \boldsymbol{w^*}}}{\llnorm{\boldsymbol{w}} \llnorm{\boldsymbol{w^*}}} \\
            &amp; \geq \frac{M \gamma}{\sqrt{M C^2} \times 1} \\
            &amp; = \sqrt{M} \frac{\gamma}{C}
        \end{split}
    \end{equation}

    which means $M \leq \frac{C^2}{\gamma^2}$.
\end{question}

\begin{question}[Perceptron Loss]
    \begin{equation}
        \begin{split}
            l(\boldsymbol{w}, \boldsymbol{x_t}, y_t) 
            &amp; = -y_t \iprod{\boldsymbol{w}, \boldsymbol{x_t}} \mathbb{I}[\text{mistake on }\boldsymbol{x_t}] \\
            &amp; = -\min \left\{ y_t \iprod{\boldsymbol{w}, \boldsymbol{x_i}}, 0 \right\}
        \end{split}
    \end{equation}
    \begin{equation}
        L(\boldsymbol{w}) = -\frac{1}{n} \sum_{t=1}^n y_t \iprod{\boldsymbol{w}, \boldsymbol{x_t}} \mathbb{I} [\text{mistake on }\boldsymbol{x_t}]
    \end{equation}
\end{question}

\section{Linear Regression}

\begin{question}[Least Square Regression]
   \begin{equation}
    \min_{f: \mathcal{X} \rightarrow \mathcal{Y}} \mathbb{E} \llnorm{f(\boldsymbol{X}) - Y}^2
   \end{equation} 

   The optimal regression function is
   \begin{equation}
    f^*(\boldsymbol{x}) = m(x) = \mathbb{E} [Y | \boldsymbol{X} = \boldsymbol{x}]
   \end{equation}

   Calculating it needs to know the distribution, i.e., all pairs $(\boldsymbol{X}, Y)$.
\end{question}

\begin{question}[Bias-Variance Decomposition]
    \begin{equation}
        \begin{split}
            \mathbb{E} \llnorm{f(\boldsymbol{X}) - Y}^2
            &amp; = \mathbb{E} \llnorm{f(\boldsymbol{X}) - m(x) + m(x) - Y}^2 \\
            &amp; = \mathbb{E} \llnorm{f(\boldsymbol{X}) - m(x)}^2 + \mathbb{E} \llnorm{m(x) - Y}^2 + 2 \mathbb{E} \iprod{f(\boldsymbol{X}) - m(x), m(x) - Y} \\
            &amp; = \mathbb{E} \llnorm{f(\boldsymbol{X}) - m(x)}^2 + \mathbb{E} \llnorm{m(x) - Y}^2 + \mathbb{E} \; \mathbb{E}_{Y|\boldsymbol{X}} \left[ \iprod{f(\boldsymbol{X}) - m(x), m(x) - Y} \right] \\
            &amp; = \mathbb{E} \llnorm{f(\boldsymbol{X}) - m(x)}^2 + \mathbb{E} \llnorm{m(x) - Y}^2 + \mathbb{E} \iprod{f(\boldsymbol{X}) - m(x), m(x) - \mathbb{E}_{Y|\boldsymbol{X}} [Y]} \\
            &amp; = \mathbb{E} \llnorm{f(\boldsymbol{X}) - m(x)}^2 + \mathbb{E} \llnorm{m(x) - Y}^2 + \mathbb{E} \iprod{f(\boldsymbol{X}) - m(x), m(x) - m(x)} \\
            &amp; = \mathbb{E} \llnorm{f(\boldsymbol{X}) - m(x)}^2 + \underbrace{\mathbb{E} \llnorm{m(x) - Y}^2}_{\text{noise (variance)}}
        \end{split}
    \end{equation} 

    The last term is the noise (variance), irrelevant to $f$. 
    So, to minimize the squared error, we need $f \approx m$.

    However, $m(\boldsymbol{x})$ is incalculable, because $\mathbb{E} [Y | \boldsymbol{X} = \boldsymbol{x}]$ is unknown.

    Let's learn $f_D$ from the training data $D$. Define $\bar{f}(\boldsymbol{X}) = \mathbb{E}_D[f_D(\boldsymbol{X})]$.
    \begin{equation}
        \begin{split}
            \underbrace{\mathbb{E}_{\boldsymbol{X}, Y, D} \llnorm{f_D(\boldsymbol{X}) - Y}^2}_{\text{test error}}
            &amp; = \mathbb{E}_{\boldsymbol{X}} \llnorm{f_D(\boldsymbol{X}) - m(x)}^2 + \underline{\mathbb{E}_{\boldsymbol{X}, Y} \llnorm{m(x) - Y}^2} \\
            &amp; = \mathbb{E}_{\boldsymbol{X}, D} \llnorm{f_D(\boldsymbol{X}) - \bar{f}(\boldsymbol{X}) + \bar{f}(\boldsymbol{X}) - m(x)}^2 + \underline{\mathbb{E}_{\boldsymbol{X}, Y} \llnorm{m(x) - Y}^2} \\
            &amp; = \mathbb{E}_{\boldsymbol{X}, D} \llnorm{f_D(\boldsymbol{X}) - \bar{f}(\boldsymbol{X})}^2 + \mathbb{E}_{\boldsymbol{X}} \llnorm{\bar{f}(\boldsymbol{X}) - m(x)}^2 \\
               &amp; \qquad + 2 \mathbb{E}_{\boldsymbol{X}, D} \iprod{f_D(\boldsymbol{X}) - \bar{f}(\boldsymbol{X}), \bar{f}(\boldsymbol{X}) - m(x)} \\
               &amp; \qquad + \underline{\mathbb{E}_{\boldsymbol{X}, Y} \llnorm{m(x) - Y}^2} \\
            &amp; = \dots + 2 \mathbb{E}_{\boldsymbol{X}} \mathbb{E}_{D} \iprod{f_D(\boldsymbol{X}) - \bar{f}(\boldsymbol{X}), \bar{f}(\boldsymbol{X}) - m(x)} + \underline{\dots} \\
            &amp; = \dots + 2 \mathbb{E}_{\boldsymbol{X}} \iprod{\mathbb{E}_{D} [f_D(\boldsymbol{X})] - \bar{f}(\boldsymbol{X}), \bar{f}(\boldsymbol{X}) - m(x)} + \underline{\dots} \\
            &amp; = \dots + 2 \mathbb{E}_{\boldsymbol{X}} \iprod{\bar{f}(\boldsymbol{X}) - \bar{f}(\boldsymbol{X}), \bar{f}(\boldsymbol{X}) - m(x)} + \underline{\dots} \\
            &amp; = \dots + 0 + \underline{\dots} \\
            &amp; = \mathbb{E}_{\boldsymbol{X}, D} \llnorm{f_D(\boldsymbol{X}) - \bar{f}(\boldsymbol{X})}^2 + \mathbb{E}_{\boldsymbol{X}} \llnorm{\bar{f}(\boldsymbol{X}) - m(x)}^2 + \underline{\mathbb{E}_{\boldsymbol{X}, Y} \llnorm{m(x) - Y}^2} \\
            &amp; = \underbrace{\mathbb{E}_{\boldsymbol{X}, D} \llnorm{f_D(\boldsymbol{X}) - \mathbb{E}_D [f_D(\boldsymbol{X})]}^2}_{\text{variance}} + \underbrace{\mathbb{E}_{\boldsymbol{X}} \llnorm{\mathbb{E}_D [f_D(\boldsymbol{X})] - m(x)}^2}_{\text{bias}^2} + \underbrace{\mathbb{E}_{\boldsymbol{X}, Y} \llnorm{m(x) - Y}^2}_{\text{noise (variance)}} \\
        \end{split}
    \end{equation}
\end{question}

\begin{question}[Sampling $\rightarrow$ Training]
    Replace expectation with sample average: $\paren{\boldsymbol{X_i}, Y_i} \tilde P$.
    \begin{equation}
        \min_{f: \mathcal{X} \rightarrow \mathcal{Y}} \hat{\mathbb{E}} \llnorm{f(\boldsymbol{X}) - Y}^2 \coloneq \frac{1}{n} \sum_{i=1}^n \llnorm{f(\boldsymbol{X_i}) - Y_i}^2
    \end{equation}
    Uniform law of large numbers: as training data size $n \rightarrow \argmin \mathbb{E}$, 

    $\hat{\mathbb{E}} \rightarrow \mathbb{E}$ and (hopefully) $\argmin \hat{\mathbb{E}} \rightarrow \mathbb{E}$.
\end{question}

\begin{question}[Linear Regression]
    Padding: $\boldsymbol{x} \leftarrow \begin{pmatrix}\boldsymbol{x} \\ 1\end{pmatrix}$, $W \leftarrow \begin{pmatrix}W \\ \boldsymbol{b}\end{pmatrix}$
    \begin{align*}
    X &amp; = [\boldsymbol{x_1}, \dots, \boldsymbol{x_n}] \in \mathbb{R}^{(d+1) \times n}, \\
    Y &amp; = [\boldsymbol{y_1}, \dots, \boldsymbol{y_n}] \in \mathbb{R}^{t \times n}, \\
    W &amp; \in \mathbb{R}^{t \times (d+1)}, \\
    \fnorm{A} &amp; = \sqrt{\sum_{ij} a_{ij}^2}
    \end{align*}
    Linear regression is:
    \begin{equation}
        \min_{W \in \mathbb{R}^{t \times (d+1)}} \frac{1}{n} \fnorm{WX - Y}^2
    \end{equation}
\end{question}

\begin{question}[Optimality Condition]
    If $\boldsymbol{w}$ is a minimizer (or maximizer) of a differentiable function $f$
    \textbf{over an open set}, then $f'(\boldsymbol{w}) = 0$.
\end{question}

\begin{question}[Solving Linear Regression]
    \begin{equation}
        L(W) = \frac{1}{n} \fnorm{WX-Y}^2
    \end{equation}
    \begin{equation}
        \begin{split}
            \nabla_W L(W) &amp; = \frac{2}{n} (WX-Y) X^T = 0 \\
            &amp; \Rightarrow W X X^T = Y X^T \\
            &amp; \Rightarrow W = Y X^T (X X^T)^{-1} \\
        \end{split}
    \end{equation}
\end{question}

\begin{question}[Ill-Conditioning]
    Slight pertubation leads to chaotic behavior, which happens whenever
    $X$ is ill-conditioned, i.e., (close to) rank-deficient.

    \vspace{5mm}
    Rank-deficient X means:
    \begin{enumerate}
        \item two columns in $X$ are linearly dependent (or simply the same)
        \item but the corresponding $y$ might be different
    \end{enumerate}
\end{question}

\begin{question}[Ridge Regression]
    \begin{equation}
        \min_{W} \frac{1}{n} \fnorm{WX - Y}^2 + \lambda \fnorm{W}^2
    \end{equation}
    \begin{equation}
        \begin{split}
            \nabla_W L(W) &amp; = \frac{2}{n} (WX - Y) X^T + 2 \lambda W = 0 \\
            &amp; \Rightarrow W X X^T - Y X^T + \lambda W = 0 \\
            &amp; \Rightarrow W (X X^T + n \lambda I) = Y X^T
        \end{split}
    \end{equation}
    \begin{equation}
        \begin{split}
            &amp; X = U \Sigma V^T \\
            \Rightarrow &amp; X X^T = U \Sigma (V^T V) \Sigma U^T = U \Sigma^2 U^T \\
            \Rightarrow &amp; X X^T + n \lambda I = U \underbrace{(\Sigma^2 + n \lambda I)}_{\text{strictly positive}} U^T \\
            \Rightarrow &amp; X X^T + n \lambda I \text{ is of full-rank}
        \end{split}
    \end{equation}

    $\lambda$ is regularization parameter. $\lambda = \infty \Rightarrow W \equiv \boldsymbol{0}$.
\end{question}

\begin{question}[Regularization $\equiv$ Data Augmentation]
    \begin{equation}
        \frac{1}{n} \fnorm{WX - Y}^2 + \lambda \fnorm{W}^2
        = \frac{1}{n} \fnorm{W \left[X \quad \sqrt{n\lambda} I \right] - \left[Y \quad \boldsymbol{0}\right]}^2
    \end{equation}
\end{question}

\section{Logistic Regression}

\begin{question}[Max Likelihood Estimation]
    Let $\mathcal{Y} = \{0, 1\}$. 
    Learn confidence $p(\boldsymbol{x}; \boldsymbol{w}) \coloneq \Pr (Y=1|X=\boldsymbol{x})$.

    \begin{equation}
        \begin{split}
            \max_{\boldsymbol{w}} \Pr (Y_1 = y_1, \dots, Y_n = y_n)
            &amp; = \max_{\boldsymbol{w}} \prod_{i=1}^n \Pr (Y_i = y_i | X_i = x_i) \\
            &amp; \stackrel{\mathcal{Y}=\{0, 1\}}{=} \max_{\boldsymbol{w}} \prod_{i=1}^n \left[p(\boldsymbol{x_i}; \boldsymbol{w})\right]^{y_i} \left[1 - p(\boldsymbol{x_i}; \boldsymbol{w})\right]^{1 - y_i} \\
        \end{split}
    \end{equation}

    Use negative log-likelihood:

    \begin{equation}
        \min_{\boldsymbol{w}} \sum_{i=1}^n \left[ -y_i \log p(\boldsymbol{x_i}; \boldsymbol{w}) - (1 - y_i) \log (1 - p(\boldsymbol{x_i}; \boldsymbol{w})) \right]
    \end{equation}
\end{question}

\begin{question}[Odds Ratio and Sigmoid]
    \begin{equation}
        \text{Odds Ratio} = \frac{\Pr}{1 - \Pr}
    \end{equation}

    Assume $\log \frac{p(\boldsymbol{x};\boldsymbol{w})}{1 - p(\boldsymbol{x};\boldsymbol{w})} = \iprod{\boldsymbol{x}, \boldsymbol{w}}$.

    \vspace{5mm}
    The Sigmoid transformation is:
    \begin{equation}
        p(\boldsymbol{x}; \boldsymbol{w}) = \frac{1}{1 + \exp (-\iprod{\boldsymbol{x}, \boldsymbol{w}})}
    \end{equation}
\end{question}

\begin{question}[Logistic Regression]
    Plug the sigmoid in the negative log-likelihood:
    \begin{equation}
        \begin{split}
        &amp; \min_{\boldsymbol{w}} \sum_{i=1}^n \left[ -y_i \log p(\boldsymbol{x_i}; \boldsymbol{w}) - (1 - y_i) \log (1 - p(\boldsymbol{x_i}; \boldsymbol{w})) \right] \\
        = &amp; \min_{\boldsymbol{w}} \sum_{i=1}^n \left[ y_i \log [1 + \exp(-\iprod{\boldsymbol{x_i}, \boldsymbol{w}})] - (1 - y_i) \log \left(1 - \frac{1}{1 + \exp (-\iprod{\boldsymbol{x_i}, \boldsymbol{w}})}\right) \right] \\
        = &amp; \min_{\boldsymbol{w}} \sum_{i=1}^n \left[ y_i \log [1 + \exp(-\iprod{\boldsymbol{x_i}, \boldsymbol{w}})] - (1 - y_i) \log \left(\frac{\exp (-\iprod{\boldsymbol{x_i}, \boldsymbol{w}})}{1 + \exp (-\iprod{\boldsymbol{x}, \boldsymbol{w}})}\right) \right] \\
        = &amp; \min_{\boldsymbol{w}} \sum_{i=1}^n \left[ y_i \log [1 + \exp(-\iprod{\boldsymbol{x_i}, \boldsymbol{w}})] + (1 - y_i) \left[\iprod{\boldsymbol{x_i}, \boldsymbol{w}} + \log(1 + \exp (-\iprod{\boldsymbol{x}, \boldsymbol{w}}))\right] \right] \\
        = &amp; \min_{\boldsymbol{w}} \sum_{i=1}^n \left[ \log [1 + \exp(-\iprod{\boldsymbol{x_i}, \boldsymbol{w}})] + (1 - y_i) \iprod{\boldsymbol{x_i}, \boldsymbol{w}} \right] \\
        \end{split}
    \end{equation}
    Because $y_i \in \{0, 1\}$, let's map it to $\{\pm 1\}$.
    \begin{equation}
        \begin{split}
            L(\boldsymbol{w})
            &amp; \stackrel{y_i \in \{0, 1\}}{=} \log [1 + \exp(-\iprod{\boldsymbol{x_i}, \boldsymbol{w}})] + (1 - y_i) \iprod{\boldsymbol{x_i}, \boldsymbol{w}} \\
            &amp; \stackrel{y_i \in \{0, 1\}}{=} \log [1 + \exp(-\iprod{\boldsymbol{x_i}, \boldsymbol{w}})] + \log \left[ \exp ( (1 - y_i) \iprod{\boldsymbol{x_i}, \boldsymbol{w}} ) \right] \\
            &amp; \stackrel{y_i \in \{0, 1\}}{=} \log [1 + \exp(-\iprod{\boldsymbol{x_i}, \boldsymbol{w}}) \cdot \exp ( (1 - y_i) \iprod{\boldsymbol{x_i}, \boldsymbol{w}} ) ] \\
            &amp; \stackrel{y_i \in \{0, 1\}}{=} \log [\exp((1-y_i)\iprod{\boldsymbol{x_i}, \boldsymbol{w}}) + \exp(-y_i \iprod{\boldsymbol{x_i}, \boldsymbol{w}})] \\
            &amp; \stackrel{y_i \in \{0, 1\}}{=} \begin{cases}
                \log [\exp(\iprod{\boldsymbol{x_i}, \boldsymbol{w}}) + 1] &amp; y_i = 0 \\
                \log [1 + \exp(-\iprod{\boldsymbol{x_i}, \boldsymbol{w}})] &amp; y_i = 1
            \end{cases} \\
            &amp; \stackrel{y_i \in \{\pm 1\}}{=} \log [ 1 + \exp(-y_i \iprod{\boldsymbol{x_i}, \boldsymbol{w}}) ]
        \end{split}
    \end{equation}
\end{question}

\begin{question}[Multi-Class: Sigmoid $\rightarrow$ Softmax]
    \begin{equation}
        \Pr(Y=k | X = \boldsymbol{x}; \boldsymbol{W} = [\boldsymbol{w_1}, \dots, \boldsymbol{w_c}])
        = \frac{\exp(\iprod{\boldsymbol{x}, \boldsymbol{w_k}})}{\sum_{l=1}^c \exp(\iprod{\boldsymbol{x}, \boldsymbol{w_l}})}
    \end{equation}
    Maximum likelihood estimation (log loss, cross-entropy loss):
    \begin{equation}
        \min_{\boldsymbol{W}} \sum_{i=1}^n \left[ -\log \frac{\exp(\iprod{\boldsymbol{x}, \boldsymbol{w_k}})}{\sum_{l=1}^c \exp(\iprod{\boldsymbol{x}, \boldsymbol{w_l}})} \right]
    \end{equation}
\end{question}

\section{Hard-Margin Support Vector Machines}

\begin{question}[Distance from a Point to a Hyperplane]
    Let $H \coloneq \{\boldsymbol{x}: \iprod{\boldsymbol{x}, \boldsymbol{w}} + b = 0\}$, $\boldsymbol{x}$ be any vector in $H$.
    \begin{equation}
        \text{Distance}(\boldsymbol{x_i}, \boldsymbol{w})
        = \frac{|\iprod{\boldsymbol{x_i} - \boldsymbol{x}, \boldsymbol{w}}|}{\llnorm{\boldsymbol{w}}}
        = \frac{|\iprod{\boldsymbol{x_i}, \boldsymbol{w}} - \iprod{\boldsymbol{x}, \boldsymbol{w}}|}{\llnorm{\boldsymbol{w}}}
        \stackrel{\boldsymbol{x} \in H}{=} \frac{|\iprod{\boldsymbol{x_i}, \boldsymbol{w}} + b|}{\llnorm{\boldsymbol{w}}}
        \stackrel{y_i \hat{y_i} &gt; 0}{=} \frac{y_i \hat{y_i}}{\llnorm{\boldsymbol{w}}}
    \end{equation}
\end{question}

\begin{question}[Margin Maximization]
    Margin is the smallest distance to $H$ among all separable data.
    \begin{equation}
        \max_{\boldsymbol{w}, b} \min_i \frac{y_i \hat{y_i}}{\llnorm{\boldsymbol{w}}} 
        \text{, such that }
        \forall i, y_i \hat{y_i} &gt; 0
    \end{equation}
    Let $c &gt; 0$, then $\boldsymbol{w} = c\boldsymbol{w}, b = cb$ keeps the loss same:
    \begin{equation}
        \begin{split}
            \max_{\boldsymbol{w}, b} \min_i \frac{c y_i \hat{y_i}}{\llnorm{c\boldsymbol{w}}} 
            &amp; = \max_{\boldsymbol{w}, b} \min_i \frac{y_i (\iprod{\boldsymbol{x}, c\boldsymbol{w}} + cb)}{\llnorm{c\boldsymbol{w}}} \\
            &amp; = \max_{\boldsymbol{w}, b} \min_i \frac{c y_i (\iprod{\boldsymbol{x}, \boldsymbol{w}} + b)}{c \llnorm{\boldsymbol{w}}} \\
            &amp; = \max_{\boldsymbol{w}, b} \min_i \frac{y_i (\iprod{\boldsymbol{x}, \boldsymbol{w}} + b)}{\llnorm{\boldsymbol{w}}} \\
            &amp; = \max_{\boldsymbol{w}, b} \min_i \frac{y_i \hat{y_i}}{\llnorm{\boldsymbol{w}}} 
        \end{split}
    \end{equation}
    Let $c = \frac{1}{\min_i y_i \hat{y_i}}$,
    \begin{equation}
        \begin{split}
            \max_{\boldsymbol{w}, b} \min_i \frac{c y_i \hat{y_i}}{c \llnorm{\boldsymbol{w}}} 
            &amp; = \max_{\boldsymbol{w}, b} \frac{1}{c \llnorm{\boldsymbol{w}}} \\
            &amp; = \max_{\boldsymbol{w}, b} \frac{1}{\llnorm{\boldsymbol{w}}} \text{ s.t. } \min_i y_i \hat{y_i} = 1
        \end{split}
    \end{equation}
    Max $\rightarrow$ Min:
    \begin{equation}
        \min_{\boldsymbol{w}, b} \frac{1}{2} \llnorm{\boldsymbol{w}}^2 \text{ s.t. } \forall i, y_i \hat{y_i} \geq 1
    \end{equation}
\end{question}

\begin{question}[Hard-Margin SVM v.s. Perceptron]
    \begin{align}
        \text{Hard-Margin SVM:} \qquad
        &amp; \min_{\boldsymbol{w}, b} \frac{1}{2} \llnorm{\boldsymbol{w}}^2 &amp; \text{ s.t. } \forall i, y_i \hat{y_i} \geq 1 \\
        \text{Perceptron:} \qquad
        &amp; \min_{\boldsymbol{w}, b} 0 &amp; \text{ s.t. } \forall i, y_i \hat{y_i} \geq 1
    \end{align}
\end{question}

\begin{question}[Lagrangian Dual]
    Dual variables $\boldsymbol{\alpha} \in \mathbb{R}^n$.
    \begin{equation}
        \begin{split}
            \min_{\boldsymbol{w}, b} \; \max_{\boldsymbol{\alpha} \geq 0} \; \frac{1}{2} \llnorm{\boldsymbol{w}}^2 - \sum_i \alpha_i \left[ y_i (\iprod{\boldsymbol{x_i}, \boldsymbol{w}} + b) - 1 \right] 
            &amp; = \min_{\boldsymbol{w}, b} \; \begin{cases}
                + \infty, &amp; \text{if } \exists i, y_i (\iprod{\boldsymbol{x_i}, \boldsymbol{w}} + b) &lt; 1 \quad (\alpha_i = + \infty) \\
                \frac{1}{2} \llnorm{\boldsymbol{w}}^2 , &amp; \text{if } \forall i, y_i (\iprod{\boldsymbol{x_i}, \boldsymbol{w}} + b) \geq 1 \quad (\forall i, \alpha_i = 0) \\
            \end{cases} \\
            &amp; = \min_{\boldsymbol{w}, b} \; \frac{1}{2} \llnorm{\boldsymbol{w}}^2, \quad \text{s.t. } \forall i, y_i (\iprod{\boldsymbol{x_i}, \boldsymbol{w}} + b) \geq 1 \\
            &amp; = \min_{\boldsymbol{w}, b} \frac{1}{2} \llnorm{\boldsymbol{w}}^2 \text{ s.t. } \forall i, y_i \hat{y_i} \geq 1
        \end{split}
    \end{equation}

    Swap $\min$ and $\max$:
    \begin{equation} \label{lagrangian-max-min}
        \max_{\boldsymbol{\alpha} \geq 0} \; \min_{\boldsymbol{w}, b} \; \frac{1}{2} \llnorm{\boldsymbol{w}}^2 - \sum_i \alpha_i \left[ y_i (\iprod{\boldsymbol{x_i}, \boldsymbol{w}} + b) - 1 \right] 
    \end{equation}

    Solve inner problem by setting derivative to 0:
    \begin{equation} \label{solve-derivative-for-svm-dual}
        \frac{\delta}{\delta \boldsymbol{w}} = \boldsymbol{w} - \sum_i \alpha_i y_i \boldsymbol{x_i} = 0,
        \qquad
        \frac{\delta}{\delta b} = - \sum_i \alpha_i y_i = 0,
    \end{equation}

    Plug them into the loss:
    \begin{equation}
        \begin{split}
            L(\boldsymbol{\alpha}) 
            &amp; = \min_{\boldsymbol{w}, b} \; \frac{1}{2} \llnorm{\boldsymbol{w}}^2 - \sum_i \alpha_i \left[ y_i (\iprod{\boldsymbol{x_i}, \boldsymbol{w}} + b) - 1 \right] \\
            &amp; = \frac{1}{2} \llnorm{\sum_i \alpha_i y_i \boldsymbol{x_i}}^2 - \sum_i \alpha_i y_i \iprod{\boldsymbol{x_i}, \boldsymbol{w}} - \sum_i \alpha_i y_i b + \sum_i \alpha_i \\
            &amp; = \frac{1}{2} \llnorm{\sum_i \alpha_i y_i \boldsymbol{x_i}}^2 - \iprod{\sum_i \alpha_i y_i \boldsymbol{x_i}, \sum_i \alpha_i y_i \boldsymbol{x_i}} - b \sum_i \alpha_i y_i + \sum_i \alpha_i \\
            &amp; = \frac{1}{2} \llnorm{\sum_i \alpha_i y_i \boldsymbol{x_i}}^2 - \llnorm{\sum_i \alpha_i y_i \boldsymbol{x_i}}^2 + \sum_i \alpha_i \\
            &amp; = \sum_i \alpha_i - \frac{1}{2} \llnorm{\sum_i \alpha_i y_i \boldsymbol{x_i}}^2,
            \qquad \text{s.t. } \sum_i \alpha_i y_i = 0
        \end{split}
    \end{equation}

    So, \ref{lagrangian-max-min} is solved as:
    \begin{equation}
        \max_{\boldsymbol{\alpha} \geq 0} \sum_i \alpha_i - \frac{1}{2} \llnorm{\sum_i \alpha_i y_i \boldsymbol{x_i}}^2, 
        \qquad \text{s.t. } \sum_i \alpha_i y_i = 0
    \end{equation}

    Max $\rightarrow$ min and expand the norm:
    \begin{equation}
        \min_{\boldsymbol{\alpha} \geq 0} - \sum_i \alpha_i + \frac{1}{2} \sum_i \sum_j \alpha_i \alpha_j y_i y_j \underbrace{\iprod{\boldsymbol{x_i}, \boldsymbol{x_j}}}_{\text{Kernel, closed form w.r.t. }\boldsymbol{x_i}, \boldsymbol{x_j}}, 
        \qquad \text{s.t. } \sum_i \alpha_i y_i = 0
    \end{equation}
\end{question}

\begin{question}[Support Vectors]
    From \ref{solve-derivative-for-svm-dual}, we know $\boldsymbol{w} = \sum_i \alpha_i y_i \boldsymbol{x_i}$.

    Vectors with $\alpha_i \neq 0$ are support vectors, which lie on the margin.
\end{question}

\section{Soft-Margin Support Vector Machines}

\begin{question}[Goal]
    minimize over $\boldsymbol{w}, b$,
    \begin{equation}
        \Pr(Y \neq \sign(\hat Y)) = \Pr(Y \hat Y \leq 0)
        = \mathbb{E} \; \underbrace{\mathbb{I} [Y \hat Y \leq 0]}_{indicator function}
        \coloneq \mathbb{E} \; l_{0-1}(Y \hat Y)
    \end{equation}
    where $\hat Y = \iprod{X, \boldsymbol{w}} + b, Y = \pm 1$.

    \begin{equation}
        \begin{split}
            \min_{\hat Y: \mathcal{X} \rightarrow \mathbb{R}} \mathbb{E} \; l_{0-1}(Y \hat Y)
            &amp; = \min_{\hat Y: \mathcal{X} \rightarrow \mathbb{R}} \mathbb{E}_X \mathbb{E}_{Y|X} \; l_{0-1}(Y \hat Y) \\
            &amp; = \mathbb{E}_X \min_{\hat Y: \mathcal{X} \rightarrow \mathbb{R}} \mathbb{E}_{Y|X} \; l_{0-1}(Y \hat Y) \\
        \end{split}
    \end{equation}

    Minimizing the 0-1 error is \textbf{NP-hard}.
\end{question}

\begin{question}[Bayes Rule]
    \begin{equation}
        \eta(\boldsymbol{x}) \coloneq \argmax_{\hat y \in \mathbb{R}} \Pr (Y = \hat y | X = \boldsymbol{x})
    \end{equation}
    \begin{equation}
        \eta(\boldsymbol{x}) \coloneq \argmin_{\hat y \in \mathbb{R}} \mathbb{E}_{Y|X=\boldsymbol{x}} \; l_{0-1}(Y \hat y)
    \end{equation}
\end{question}

\begin{question}[Classification Calibrated]
    A loss $l(y \hat y)$ is classification calibrated, iff $\forall \boldsymbol{x}$,
    \begin{equation*}
    \hat y(\boldsymbol{x}) \coloneq \argmin_{\hat y \in \mathbb{R}} \mathbb{E}_{Y | X = \boldsymbol{x}} \; l(Y \hat y)
    \end{equation*}
    has the same sign as the Bayes rule $\eta(\boldsymbol{x}) \coloneq \argmin_{\hat y \in \mathbb{R}} \mathbb{E}_{Y|X=\boldsymbol{x}} \; l_{0-1}(Y \hat y)$

    Notice: $\eta(\boldsymbol{x}), \hat y (\boldsymbol{x})$ provide the \textbf{score}, their sign provides the prediction.
\end{question}

\begin{question}[Characterization under Convexity]
    Any \textbf{convex} loss $l$ is classification calibrated iff $l$ is differentiable
    at $0$ and $l'(0) &lt; 0$.
\end{question}

\begin{question}[Hinge Loss]
    \begin{equation}
        l_{hinge}(y \hat y) = (1 - y \hat y)^+ \coloneq \max \{0, 1 - y \hat y\}
        = \begin{cases}
            1 - y \hat y, &amp; \text{if } y \hat y &lt; 1 \\
            0, &amp; \text{otherwise}
        \end{cases}
    \end{equation}
    The classifier that minimizes the expected hinge loss minimizes the expected 0-1 loss.
\end{question}

\begin{question}[Soft-Margin SVM]
    \begin{equation}
        \min_{\boldsymbol{w}, b} \frac{1}{2} \llnorm{\boldsymbol{w}}^2 + C \cdot \sum_i l_{hinge}(y_i \hat y_i), \quad \text{s.t. } \hat y_i = \iprod{\boldsymbol{x_i}, \boldsymbol{w}} + b
    \end{equation}
\end{question}
    

\begin{question}[Lagrangian Dual]
    Apply $C \cdot l_{hinge}(t) \coloneq \max\{0, C(1 - t)\} = \max_{0 \leq \alpha \leq C} \alpha (1 - t)$
    \begin{equation}
        \min_{\boldsymbol{w}, b} \max_{0 \leq \boldsymbol{\alpha} \leq C} \frac{1}{2} \llnorm{\boldsymbol{w}}^2 + \sum_i \alpha_i (1 - y_i \hat y_i)
    \end{equation}

    Swap $\min$ with $\max$:
    \begin{equation}
        \max_{0 \leq \boldsymbol{\alpha} \leq C} \min_{\boldsymbol{w}, b} \frac{1}{2} \llnorm{\boldsymbol{w}}^2 + \sum_i \alpha_i (1 - y_i \hat y_i)
    \end{equation}

    Solve it by setting derivative to 0:
    \begin{equation} 
        \frac{\delta}{\delta \boldsymbol{w}} = \boldsymbol{w} - \sum_i \alpha_i y_i \boldsymbol{x_i} = 0,
        \qquad
        \frac{\delta}{\delta b} = - \sum_i \alpha_i y_i = 0,
    \end{equation}

    Plug them into the loss:
    \begin{equation}
        \begin{split}
            \max_{0 \leq \boldsymbol{\alpha} \leq C} \min_{\boldsymbol{w}, b} \frac{1}{2} \llnorm{\boldsymbol{w}}^2 + \sum_i \alpha_i (1 - y_i \hat y_i)
            &amp; = \max_{0 \leq \boldsymbol{\alpha} \leq C} \min_{\boldsymbol{w}, b} \; \frac{1}{2} \llnorm{\boldsymbol{w}}^2 + \sum_i \alpha_i \left[ 1 - y_i (\iprod{\boldsymbol{x_i}, \boldsymbol{w}} + b) \right] \\
            &amp; = \max_{0 \leq \boldsymbol{\alpha} \leq C} \sum_i \alpha_i - \frac{1}{2} \llnorm{\sum_i \alpha_i y_i \boldsymbol{x_i}}^2,
            \qquad \text{s.t. } \sum_i \alpha_i y_i = 0
        \end{split}
    \end{equation}

    Max $\rightarrow$ min and expand the norm:
    \begin{equation}
        \min_{0 \leq \boldsymbol{\alpha} \leq C} - \sum_i \alpha_i + \frac{1}{2} \sum_i \sum_j \alpha_i \alpha_j y_i y_j \underbrace{\iprod{\boldsymbol{x_i}, \boldsymbol{x_j}}}_{\text{Kernel, closed form w.r.t. }\boldsymbol{x_i}, \boldsymbol{x_j}}, 
        \qquad \text{s.t. } \sum_i \alpha_i y_i = 0
    \end{equation}

    $C \rightarrow \infty \Rightarrow \text{Hard-margin SVM}$,
    $C \rightarrow 0 \Rightarrow \text{a constant classifier}$
\end{question}

\section{Reproducing Kernels}

\begin{question}[(Reproducing) Kernels]
    $k: \mathcal(X) \times \mathcal{X} \rightarrow \mathbb{R}$ is a (reproducing) kernel
    iff there exists some $\Phi: \mathcal{X} \rightarrow \mathcal{H}$ so that
    $\iprod{\Phi(\boldsymbol{x}), \Phi(\boldsymbol{z})} = k(\boldsymbol{x}, \boldsymbol{z})$.
    
    \begin{itemize}
        \item A feature transform $\Phi$ determines the corresponding kernel $k$.
        \item A kernel $k$ determines some feature transforms $\Phi$, but may not be unique. \\
        E.g. $\iprod{\phi(\boldsymbol{x}), \phi(\boldsymbol{z})} = \iprod{\phi'(\boldsymbol{x}), \phi'(\boldsymbol{z})}$
        \begin{enumerate}
            \item $\phi(x) \coloneq [x_1^2, \sqrt{2} x_1 x_2] \in \mathbb{R}^2$
            \item $\phi'(x) \coloneq [x_1^2, x_1 x_2, x_1 x_2] \in \mathbb{R}^3$
        \end{enumerate}
    \end{itemize}
\end{question}

\begin{question}[Mercer's Theorem]
    $k: \mathcal{X} \times \mathcal{X} \rightarrow \mathbb{R}$ is a kernel, \\
    iff $\forall n \in \mathbb{N}, \forall \boldsymbol{x_1}, \dots, \boldsymbol{x_n} \in \mathcal{X}$,
    the kernel matrix $K$ such that $K_{ij} \coloneq k(\boldsymbol{x_i}, \boldsymbol{x_j})$ is symmetric and positive semi-definite (PSD).

    \begin{equation}
        k \text{ is a kernel} \Leftrightarrow \begin{cases}
            K_{ij} = K_{ji} &amp; \text{(symmetric)}\\
            \iprod{\boldsymbol{\alpha}, K \boldsymbol{\alpha}} = \sum_{i=1}^n \sum_{j=1}^n \alpha_i \alpha_j K_{ij} \geq 0 \qquad \forall \boldsymbol{\alpha} \in \mathbb{R}^n &amp; \text{(PSD)}
        \end{cases}
    \end{equation}
\end{question}

\begin{question}[Symmetric PSD]
    For a symmetric matrix $A$, the following conditions are equivalent.
    \begin{enumerate}
        \item $A \succeq 0$
        \item $A = U^T U$ for some matrix $U$
        \item $x^T A x \geq 0$ for every $x \in \mathbb{R}^n$
        \item All principal minors of $A$ are nonnegative
    \end{enumerate}
\end{question}

\section{Gradient Descent}

\begin{question}[Gradient Descent Template]
    Choose initial point $x^{(0)} \in \mathbb{R}^d$ and repeat:
    \begin{equation}
        x^{(k)} = x^{(k-1)} - \underbrace{\eta}_{\text{step size}} \nabla f(x^{(k-1)}), \quad k = 1, 2, \dots
    \end{equation}
\end{question}

\begin{question}[Interpretation from Taylor Expansion]
    Expand $f$ locally at $x$:
    \begin{equation}
        \begin{split}
            f(y) &amp; \approx f(x) + \nabla f(x)^T(y-x) + \frac{1}{2t}\llnorm{y-x}^2 \\
            \Rightarrow \min_y f(y) &amp; \approx \min_y \left[ f(x) + \nabla f(x)^T(y-x) + \frac{1}{2t}\llnorm{y-x}^2 \right] \\
        \end{split}
    \end{equation}
    When $y - x = \frac{\nabla f(x)}{-2 \frac{1}{2t}} = -t \nabla f(x) \Longrightarrow y = x - t \nabla f(x)$, it reaches the minimum.
\end{question}

\begin{question}[$L$-smooth or $L$-Lipschitz Continuous]
    $f$ is convex and differentiable. $\nabla f$ is $L$-Lipschitz continuous ($L$-smooth):
    \begin{equation}
        L \boldsymbol{I}  \succeq \nabla^2 f(x), \forall x
    \end{equation}
\end{question}

\begin{question}[Convergence Rate for Convex Case]
    Assume $f$ is $L$-smooth.
    Gradient descent with fixed step size $t \leq \frac{1}{L}$ satisfies:
    \begin{equation}
        f(x^{(k)}) - f(x^*) \leq \frac{\llnorm{x^{(0)} - x^*}^2}{2tk}
    \end{equation}
    We say gradient descent has convergence rate $O(\frac{1}{k})$,
    i.e. $f(x^{(k)}) - f(x^*) \leq \epsilon$ can be achieved using only $O(\frac{1}{\epsilon})$ iterations.

    \vspace{5mm}
    \textbf{Proof}

    \begin{equation}
        \begin{split}
            f(y) 
            &amp; = f(x) + \nabla f(x)^T (y-x) + \frac{1}{2} (y-x)^T \nabla^2 f(\xi)(y-x) \\
            &amp; \leq f(x) + \nabla f(x)^T(y-x) + \frac{1}{2} L \llnorm{y-x}^2 \qquad (L\text{-smooth}, L \boldsymbol{I} \succeq \nabla^2 f(\xi))
        \end{split}
    \end{equation}

    Plug in gradient descent:
    \begin{equation} \label{convergence-1}
        \begin{split}
            f(x^+) 
            &amp; = f(y) \\
            &amp; \leq f(x) + \nabla f(x)^T(x - t\nabla f(x)-x) + \frac{1}{2} L \llnorm{x - t\nabla f(x)-x}^2 \\
            &amp; = f(x) -(1 - \frac{1}{2}Lt) t \llnorm{\nabla f(x)}^2 \\
            &amp; \leq f(x) - \frac{1}{2} t \llnorm{\nabla f(x)}^2 \quad (t \leq \frac{1}{L})
        \end{split}
    \end{equation}

    $f$ is convex $\Rightarrow f(x^*) \geq f(x) + \nabla f(X)^T(x^* - x) \Rightarrow f(x) \leq f(x^*) + \nabla f(x)^T(x - x^*)$

    Plug this into \ref{convergence-1}:
    \begin{equation}
        \begin{split}
            &amp; f(x^+) \leq f(x^*) + \nabla f(x)^T (x - x^*) - \frac{1}{2} t \llnorm{\nabla f(x)}^2 \\
            \Rightarrow &amp; f(x^+) - f(x^*) \leq \frac{1}{2t}\left( 2t \nabla f(x)^T(x - x^*) - t^2 \llnorm{\nabla f(x)}^2 \right) \\
            \Rightarrow &amp; f(x^+) - f(x^*) \leq \frac{1}{2t}\left( 2t \nabla f(x)^T(x - x^*) - t^2 \llnorm{\nabla f(x)}^2 - \llnorm{x-x^*}^2 + \llnorm{x-x^*}^2 \right) \\
            \Rightarrow &amp; f(x^+) - f(x^*) \leq \frac{1}{2t}\left( \llnorm{x-x^*}^2 - (\llnorm{x-x^*}^2 + t^2 \llnorm{\nabla f(x)}^2 - 2t \nabla f(x)^T(x - x^*) ) \right) \\
            \Rightarrow &amp; f(x^+) - f(x^*) \leq \frac{1}{2t}\left( \llnorm{x-x^*}^2 - \llnorm{x - x^* - t\nabla f(x)}^2 \right) \\
            \Rightarrow &amp; f(x^+) - f(x^*) \leq \frac{1}{2t}\left( \llnorm{x-x^*}^2 - \llnorm{x^+ - x^*}^2 \right) \\
        \end{split}
    \end{equation}

    Viewing $x^+$ as $x^{(i)}$ and $x$ as $x^{(x-1)}$:
    \begin{equation}
        \begin{split}
            \sum_{i=1}^k \paren{ f(x^{(i)}) - f(x^*) }
            &amp; \leq \sum_{i=1}^k \frac{1}{2t} \paren{ \llnorm{x^{(i-1)} - x^*}^2 - \llnorm{x^{(i)} - x^*}^2 } \\
            &amp; = \frac{1}{2t} \paren{ \llnorm{x^{(0)} - x^*}^2 - \llnorm{x^{(k)} - x^*}^2 } \\
            &amp; \leq \frac{1}{2t} \llnorm{x^{(0)} - x^*}^2 \\
        \end{split}
    \end{equation}

    which implies
    \begin{equation}
        f(x^{(k)}) \leq \frac{1}{k} \sum_{i=1}^k f(x^{(i)}) \leq f(x^*) + \frac{\llnorm{x^{(0)} - x^*}^2}{2tk}
    \end{equation}
\end{question}

\begin{question}[Convergence Rate for Strong Convexity]
    $f$ is differentiable, $L$-smooth, and $m$-strongly convex.

    $m$-strong convexity of $f$ means $f(x) - \frac{m}{2} \llnorm{x}^2$ is convex, i.e. $\nabla^2 f(x) \succeq m \boldsymbol{I}$

    Then, there is a constant $0 &lt; \gamma &lt; 1$ such that gradient descent with fixed step size $t \leq \frac{2}{m + L}$ satisfies:
    \begin{equation}
        f(x^{(k)}) - f(x^*) \leq \gamma^k \frac{L}{2} \llnorm{x^{(0)} - x^*}^2
    \end{equation}
    Rate is $O(\gamma^k)$. Only $O(\log_{\frac{1}{\gamma}}(\frac{1}{\epsilon}))$ iterations needed.
\end{question}

\begin{question}[Convergence Rate for Non-Convex Case]
    $f$ is differentiable and $L$-smooth, but non-convex.

    Gradient descent with fixed step size $t \leq \frac{1}{L}$ satisifes:
    \begin{equation}
        \min_{i=0,\dots,k} \llnorm{\nabla f(x^{(i)})} \leq \sqrt(\frac{2 (f(x^{(0)} - f^*))}{t(k+1)})
    \end{equation}

    Rate is $O(\frac{1}{\sqrt{k}})$ for finding stationary point.
    $O(\frac{1}{\epsilon^2})$ iterations are needed.
\end{question}

\begin{question}[Convergence Rate for Stochastic Gradient Descent]
    For convex and $L$-smooth $f$,

    \begin{itemize}
        \item Gradient Descent
        \begin{equation}
            \boldsymbol{w^+} = \boldsymbol{w} - t \cdot \frac{1}{n} \sum_{i=1}^n \nabla f_i(\boldsymbol{w})
        \end{equation}
            \begin{itemize}
                \item Step size $t \leq \frac{1}{L}$
                \item Time complexity $O(\frac{n}{\epsilon})$
            \end{itemize}
        \item Stochastic Gradient Descent
        \begin{equation}
            \boldsymbol{w^+} = \boldsymbol{w} - t \cdot \nabla f_{I_{random}}(\boldsymbol{w})
        \end{equation}
            \begin{itemize}
                \item Step size $t = \frac{1}{k}, k = 1, 2, 3, \dots$ (adaptive step size)
                \item Time complexity $O(\frac{1}{\epsilon^2})$
            \end{itemize}
    \end{itemize}
\end{question}

\section{Fully-Connected Neural Networks}

\begin{question}[Forward and Backward Pass of a 2-Layer MLP]
    A 2-layer MLP ($k$ is the NN width, $c$ is the output dim):
    \begin{align}
        \boldsymbol{x} &amp; = \text{input} &amp; (\boldsymbol{x} \in \mathbb{R}^d) \\
        \boldsymbol{z} &amp; = \boldsymbol{W} \boldsymbol{x} + \boldsymbol{b_1} &amp; (\boldsymbol{W} \in \mathbb{R}^{k \times d}, \boldsymbol{z}, \boldsymbol{b} \in \mathbb{R}^k) \\
        \boldsymbol{h} &amp; = \text{ReLU}(\boldsymbol{z}) &amp; (\boldsymbol{h} \in \mathbb{R}^k) \\
        \boldsymbol{\theta} &amp; = \boldsymbol{U} \boldsymbol{h} + \boldsymbol{b_2} &amp; (\boldsymbol{U} \in \mathbb{R}^{c \times k}, \boldsymbol{\theta}, \boldsymbol{b_2} \in \mathbb{R}^c) \\
        J &amp; = \frac{1}{2} \llnorm{\boldsymbol{\theta} - \boldsymbol{y}}^2 &amp; (\boldsymbol{y} \in \mathbb{R}^c, J \in \mathbb{R})
    \end{align}
    \begin{align}
        \text{ReLU} = \begin{cases}
            x &amp; x &gt; 0 \\
            0 &amp; x \leq 0
        \end{cases} \\
        \text{ReLU}' = \begin{cases}
            1 &amp; x &gt; 0 \\
            0 &amp; x \leq 0
        \end{cases}
    \end{align}
    
    Backward pass ($\odot$ is the Hadamard product, i.e. element-wise product):
    \begin{align}
        \frac{\delta J}{\delta \boldsymbol{\theta}} &amp; = \boldsymbol{\theta} - \boldsymbol{y} \\
        \frac{\delta J}{\delta \boldsymbol{U}} &amp; = \frac{\delta J}{\delta \boldsymbol{\theta}} \circ \frac{\delta \boldsymbol{\theta}}{\delta \boldsymbol{U}} = (\boldsymbol{\theta} - \boldsymbol{y}) \boldsymbol{h}^T \\
        \frac{\delta J}{\delta \boldsymbol{b_2}} &amp; = \frac{\delta J}{\delta \boldsymbol{\theta}} \circ \frac{\delta \boldsymbol{\theta}}{\delta \boldsymbol{b_2}} = \boldsymbol{\theta} - \boldsymbol{y} \\
        \frac{\delta J}{\delta \boldsymbol{h}} &amp; = \frac{\delta J}{\delta \boldsymbol{\theta}} \circ \frac{\delta \boldsymbol{\theta}}{\delta \boldsymbol{h}} = \boldsymbol{U^T}(\boldsymbol{\theta} - \boldsymbol{y}) \\
        \frac{\delta J}{\delta \boldsymbol{z}} &amp; = \frac{\delta J}{\delta \boldsymbol{h}} \circ \frac{\delta \boldsymbol{h}}{\delta \boldsymbol{z}} = \boldsymbol{U^T}(\boldsymbol{\theta} - \boldsymbol{y}) \odot \text{ReLU}'(\boldsymbol{z}) \\
        \frac{\delta J}{\delta \boldsymbol{W}} &amp; = \frac{\delta J}{\delta \boldsymbol{z}} \circ \frac{\delta \boldsymbol{z}}{\delta \boldsymbol{W}} = \boldsymbol{U^T}(\boldsymbol{\theta} - \boldsymbol{y}) \odot \text{ReLU}'(\boldsymbol{z}) \boldsymbol{x}^T \\
        \frac{\delta J}{\delta \boldsymbol{b_1}} &amp; = \frac{\delta J}{\delta \boldsymbol{z}} \circ \frac{\delta \boldsymbol{z}}{\delta \boldsymbol{b_1}} = \boldsymbol{U^T}(\boldsymbol{\theta} - \boldsymbol{y}) \odot \text{ReLU}'(\boldsymbol{z}) \\
    \end{align}
\end{question}

\begin{question}[Universal Approximation Theorem by 2-Layer NNs]
    For any continuous function $f: \mathbb{R}^d \rightarrow \mathbb{R}^c$
    and any $\epsilon &gt; 0$,
    there exists $k \in \mathbb{N}, \boldsymbol{W} \in \mathbb{R}^{k \times d}, \boldsymbol{b} \in \mathbb{R}^k, \boldsymbol{U} \in \mathbb{R}^{c \times k}$
    such that
    \begin{equation}
        \sup_{\boldsymbol{x}} \llnorm{f(\boldsymbol{x}) - g(\boldsymbol{x})} &lt; \epsilon
    \end{equation}
    where $g(\boldsymbol{x}) = \boldsymbol{U}(\sigma(\boldsymbol{W}\boldsymbol{x} + \boldsymbol{b}))$
    and $\sigma$ is the element-wise ReLU operation.

    As long as the 2-layer MLP is wide enough, it can approximate any
    continuous function arbitrarily closely.
\end{question}

\section{Convolutional Neural Networks}

\begin{question}[Controlling the Convolution]
    Hyperparameters.

    \begin{itemize}
        \item \textbf{Filter (kernel) size}: width $times$ height.
        \item \textbf{Number of filters (kernels)}. \\
        Weights are not shared between different filters (kernels)
        \item \textbf{Stride}: how many pixels the filter moves each time.
        \item \textbf{Padding}: add zeros around the boundary of the input.
    \end{itemize}
\end{question}

\begin{question}[Size Calculation]
    \begin{align*}
        \text{Input size: } &amp; m \times n \times c_{in} \\
        \text{Filter size: } &amp; a \times b \times c_{in} \\
        \text{Stride: } &amp; s \times t \\
        \text{Padding: } &amp; p \times q
    \end{align*}

    Output size:
    \begin{equation}
        \floor*{1 + \frac{m + 2p - a}{s}} \times \floor*{1 + \frac{n + 2q - b}{t}}
    \end{equation}
\end{question}

\part{For Final}

\section{Transformer}

\begin{question}[Attention Layer Inputs and Outputs]
    Inputs: $V \in \mathcal{R}^{n \times d}$, $K \in \mathcal{R}^{n \times d}$, $Q \in \mathcal{R}^{m \times d}$,
    Outputs: an $m \times d$ matrix.

    \begin{itemize}
        \item \textbf{Self Attention}: $m = n$,
        \item \textbf{Cross Attention}: $m \neq n$ where $m$ is the sequence length of decoder, $n$ is the sequence length of encoder.
    \end{itemize}
\end{question}

\begin{question}[Attention Layer Calculation]
    \begin{equation}
        \text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d}}\right)V
    \end{equation}

    Softmax is row-wise, i.e. for each row of $QK^T$, it is normalized to sum to 1.
\end{question}

\begin{question}[Learnable Attention Layer]
    \begin{equation}
        \text{Attention}(XW^v, XW^k, XW^q) = \text{softmax}\left(\frac{XW^q(XW^k)^T}{\sqrt{d}}\right)XW^v
    \end{equation}
\end{question}

\begin{question}[RMSNorm (LLaMA's Choice)]
    \begin{equation}
        \bar{a_i} = \frac{a_i}{\text{RMS}(a)}\gamma = \frac{a_i}{\sqrt{\frac{1}{d}\sum_{j=1}^d a_j^2}}\gamma
    \end{equation}
\end{question}

\begin{question}[Transformer Loss]
    \begin{equation}
        \min_{W} \hat{\mathbb{E}}\left[ - \iprod{Y, \log \hat{Y}} \right]
    \end{equation}
    $Y$ is output sequence, one-hot; \\
    $\hat{Y}$ is the predicted probabilities
\end{question}

\begin{question}[Transformer Implementation] As following.
    \begin{lstlisting}[language=python]
import torch
import torch.nn as nn
import torch.F as F
import math

class RMSNorm(nn.Module):
  def __init__(self, hidden_dim, eps = 1e-6):
    super().__init__()
    self.eps = eps
    self.weight = nn.Parameter(torch.ones(hidden_dim))

  def forward(self, hidden_state):
    norm = hidden_state.pow(2).mean(-1, keepdim = True)
    output = hidden_state * self.weight * torch.rsqrt(norm + self.eps)
    return output

class MultiHeadAttention(nn.Module):
  def __init__(self, hidden_dim, num_heads):
    super().__init__()
    self.hidden_dim = hidden_dim
    self.num_heads = num_heads
    self.head_dim = hidden_dim // num_heads
    self.q_linear = nn.linear(hidden_dim, hidden_dim)
    self.k_linear = nn.linear(hidden_dim, hidden_dim)
    self.v_linear = nn.linear(hidden_dim, hidden_dim)
    self.o_linear = nn.linear(hidden_dim, hidden_dim)
    self.norm = RMSNorm(hidden_dim)

  def forward(self, hidden_state, mask, past_kv = None, use_cache = True):
    bs = hidden_state.shape[0]

    residual = hidden_state

    hidden_state = self.norm(hidden_state) # LLAMA style normalization

    q = self.q_linear(hidden_state) # (bs, seqlen, hidden_dim)
    k = self.k_linear(hidden_state) # (bs, seqlen, hidden_dim)
    v = self.v_linear(hidden_state) # (bs, seqlen, hidden_dim)

    q = q.view(bs, -1, self.num_heads, self.head_dim).tranpose(1, 2)
    k = k.view(bs, -1, self.num_heads, self.head_dim).tranpose(1, 2)
    v = v.view(bs, -1, self.num_heads, self.head_dim).tranpose(1, 2)
    # (bs, nums_head, seqlen, head_dim)

    q, k = apply_rope(q, k)

    # kv cache
    if past_kv is not None:
      past_k, past_v = past_kv
      k = torch.cat([past_k, k], dim = 2)
      v = torch.cat([past_v, v], dim = 2)
    new_past_kv = (k, v) if use_cache else None

    # compute attention
    attention_scores = torch.matmul(q, k.tranpose(-1, -2)) / math.sqrt(self.head_dim)
    attention_scores += mask * -1e9
    attention_scores = F.softmax(attention_scores, dim = -1)
    output = torch.matmul(attention_scores, v)

    # concat
    output = output.tranpose(1, 2).contiguous().view(bs, -1, self.hidden_dim)

    # o_linear
    output = self.o_linear(output)

    output += residual

    return output, new_past_kv if use_cache else output
    \end{lstlisting} 
\end{question}

\section{Large Language Models}

\begin{question}[BERT v.s. GPT]
    BERT is encoder; GPT is decoder.

    \begin{itemize}
        \item BERT predicts middle words; GPT predicts the next word.
        \item BERT is \textbf{NOT} auto-regressive; GPT is auto-regressive.
    \end{itemize}
\end{question}

\begin{question}[GPT -- Generative Pre-Training]
    \begin{equation}
        \min_{\Theta} \hat{\mathbb{E}} - \log \prod_{j=1}^m \Pr(x_j \vert x_1, \dots, x_{j-1}; \Theta)
    \end{equation}
\end{question}

\begin{question}[Fine-Tuning Tasks]
    Supervised fine-tuning tasks:
    \begin{equation}
        \min_{\Theta} \underbrace{- \hat{\mathbb{E}} \log \Pr(y \vert X_{1:m}; \Theta)}_{\text{task-aware supervised loss}} \underbrace{- \lambda \hat{\mathbb{E}} \log \prod_{j=1}^m \Pr(x_j \vert X_{1:j-1}; \Theta)}_{\text{pretraining loss}}
    \end{equation}
\end{question}

\begin{question}[BERT $\rightarrow$ RoBERTa]
    Training longer, with bigger batches, over more data and longer sequence.

    Removing the next sentence prediction objective.
\end{question}

\begin{question}[Sentence-BERT]
    a twin network architecture that uses BERT to derive sentence embeddings.
\end{question}

\begin{question}[GPT-2]
    1.5B parameters.

    \begin{itemize}
        \item 10x larger than GPT-1
        \item Training method is same as GPT-1.
        \item Performs on par with BERT on fine-tuning tasks.
        \item Good at zero-shot learning.
        \item Open-source.
    \end{itemize}
\end{question}

\begin{question}[GPT-3]
    175B parameters.

    \begin{itemize}
        \item 100x larger than GPT-2.
        \item Training method is same as GPT-2.
        \item New phenomenon: \textbf{in-context learning} (ICL, or few-shot learning) and \textbf{chain-of-thoughts} (CoT).
    \end{itemize}
\end{question}

\begin{question}[GPT-3.5 -- RLHF]
    Reinforcement Learning from Human Feedback (RLHF).
    \begin{itemize}
        \item state = prompt
        \item action = model output
        \item policy function = LLM
        \item reward = levels of matching human feedback
    \end{itemize}

    Pari-wise comparison loss to train reward model $r_\theta$:
    \begin{equation}
        \mathcal{L}_{\text{pair}}(\theta) = - \frac{1}{\binom{K}{2}} \mathbb{E}_{(x, y_w, y_l)} \left[ \log ( \sigma(r_\theta(x, y_w) - r_\theta(x, y_l)) ) \right]
    \end{equation}

    Proximal Policy Optimization (PPO) to maximize objective:
    \begin{equation}
        \max_{\Phi} \mathbb{E}_{(x, y)} \left[ \underbrace{r_\theta(x, y)}_{\text{maximize reward}} - \beta \underbrace{\log\left( \frac{\pi_\Phi^{\text{RL}}(y \vert x)}{\pi^{\text{SFT}}(y \vert x)}\right) }_{\text{model is close to SFT model}} + \gamma \underbrace{\mathbb{E}[\log(\pi_\Phi^{\text{RL}}(x))]}_{\text{pretraining loss}} \right]
    \end{equation}
\end{question}

\section{Speculative Sampling}

\begin{question}[Reject Sampling for Check]
    Check in parallel.

    \begin{itemize}
        \item $r \sim U(0, 1), \quad \text{if } r &lt; \underbrace{\min\left(1, \frac{p(t)}{q(t)}\right)}_{\text{accept rate}}$, next token $= t$.
        \item else: next token $= t' \sim \underbrace{\text{norm}(\max(0, p-q))}_{\text{residual distribution}}$.
    \end{itemize}
\end{question}

\begin{question}[Proof: Reject Sampling $\equiv t \sim p$]
    \begin{align}
        \begin{split}
            \min(p(t), q(t)) + \max(0, p(t) - q(t)) 
            &amp;= \begin{cases}
            p(t) + 0 &amp; \text{if } p(t) &lt; q(t) \\
            q(t) + p(t) - q(t) &amp; \text{if } p(t) \geq q(t)
            \end{cases} \\
            &amp;= p(t)
        \end{split} \\
        \Rightarrow &amp; \sum_t (\min(p(t), q(t)) + \max(0, p(t) - q(t))) = \sum_t p(t) = 1 \\
        \Rightarrow &amp; 1 - \sum_t \min(p(t), q(t)) = \sum_t \max(0, p(t) - q(t))
    \end{align}

    \begin{equation}
        \begin{split}
            \Pr(X = t) &amp;= \Pr(\tilde{X} = t) \Pr(\tilde{X}\text{ accept} \vert \tilde{X} = t) + \Pr(\tilde{X}\text{ reject}) \Pr(\tilde{\tilde{X}} = t \vert \tilde{X}\text{ reject}) \\
            &amp;= q(t) \cdot \min\left(1, \frac{p(t)}{q(t)}\right) + (1 - \Pr(\tilde{X}\text{ accept})) \cdot \text{norm}(\max(0, p(t) - q(t))) \\
            &amp;= \min\left(q(t), p(t)\right) + (1 - \sum_t \min\left(p(t), q(t)\right)) \cdot \frac{\max(0, p(t) - q(t))}{\sum_t \max(0, p(t) - q(t))} \\
            &amp;= \min\left(q(t), p(t)\right) + \max(0, p(t) - q(t)) \\
            &amp;= p(t)
        \end{split}
    \end{equation}
\end{question}

\section{Generative Adversarial Networks}

\begin{question}[Representation through Push-Forward]
    Let $r$ be any continuous distribution on $\mathbb{R}^h$.
    For any distribution $p$ on $\mathbb{R}^d$, 
    there exists push-forward maps $G: \mathbb{R}^h \rightarrow \mathbb{R}^d$ such that
    \begin{equation}
        \boldsymbol{z} \sim r \Longrightarrow G(\boldsymbol{z}) \sim p
    \end{equation}
\end{question}

\begin{question}[Discriminator's Goal]
    For a fixed generator $G$, minimize a log loss over $D$:
    \begin{itemize}
        \item If $x$ is real, minimize $-\log D(x)$;
        \item If $x$ is fake, minimize $-\log(1 - D(x))$.
    \end{itemize}

    \begin{equation}
        \min_D -\frac{1}{2} \mathbb{E}_{x \sim p_{\text{data}}} \left[\log D(x)\right] - \frac{1}{2} \mathbb{E}_{z \sim r} \left[\log(1 - D(G(z)))\right]
    \end{equation}
\end{question}

\begin{question}[Generator's Goal]
    For a fixed discriminator $D$, maximize a log loss over $G$:
    
    \begin{equation}
        \begingroup\color{red}{\max_G}\endgroup -\frac{1}{2} \mathbb{E}_{x \sim p_{\text{data}}} \left[\log D(x)\right] - \frac{1}{2} \mathbb{E}_{z \sim r} \left[\log(1 - D(G(z)))\right]
    \end{equation}
\end{question}

\begin{question}[Solver]
    \begin{equation}
        \min_G \max_D V(G, D) = \mathbb{E}_{x \sim p_{\text{data}}} \left[\log D(x)\right] + \mathbb{E}_{z \sim r} \left[\log(1 - D(G(z)))\right]
    \end{equation}

    Solved by alternative minimization-maximization:
    \begin{itemize}
        \item G step: Fix $D$ and update $G$ by one-step gradient descent
        \item D step: Fix $G$ and update $D$ by one-step gradient descent
        \item Repeat until the algorithm reaches an approximate equilibrium
    \end{itemize}
    
\end{question}

\begin{question}[Solution of $D^*$]
    Let $p_g(x)$ be the density of $x$ estimated by the generator $G$.
    For $G$ fixed, the optimal discriminator $D$ is $D_G^*(x) = \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)}$

    \textbf{Proof:}

    \begin{equation}
        \begin{split}
            V(G, D) &amp;\coloneq \mathbb{E}_{x \sim p_{\text{data}}} \left[\log D(x)\right] + \mathbb{E}_{z \sim r} \left[\log(1 - D(G(z)))\right] \\
            &amp;= \int \log D(x) p_{\text{data}}(x) dx + \int_z \log(1 - D(G(z))) p_z(z) dz \\
            &amp;= \int \underbrace{\log D(x) p_{\text{data}}(x) + p_g(x) \log(1 - D(x))}_{f(D(x))} dx
        \end{split}
    \end{equation}

    For any fixed $x$, taking derivative $= 0$:
    \begin{equation}
        \begin{split}
            f'(D(x)) &amp;= \frac{p_{\text{data}}(x)}{D(x)} - \frac{p_g(x)}{1 - D(x)} = 0 \\
            D_G^*(x) &amp;= \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)}
        \end{split}
    \end{equation}
\end{question}

\begin{question}[Solution of $G^*$]
    The global minimum of $\min_G \max_D V(G, D)$ is achieved if
    and only if $p_g = p_{\text{data}}$. The optimal objective value is $-\log4$.

    \textbf{Proof:}
    \begin{equation}
        \begin{split}
        V(G, D_G^*) &amp;= \mathbb{E}_{x \sim p_{\text{data}}} \left[\log D_G^*(x)\right] + \mathbb{E}_{z \sim r} \left[\log(1 - D_G^*(G(z)))\right] \\
        &amp;= \mathbb{E}_{x \sim p_{\text{data}}} \left[\log D_G^*(x)\right] + \mathbb{E}_{x \sim p_g} \left[\log(1 - D_G^*(x))\right] \\
        &amp;= \mathbb{E}_{x \sim p_{\text{data}}} \left[\log \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)}\right] + \mathbb{E}_{x \sim p_g} \left[\frac{p_g(x)}{p_{\text{data}}(x) + p_g(x)}\right] \\
        \end{split}
    \end{equation}

    By definition of KL divergence $\text{KL}(P \| Q) = \mathbb{E}_{x \sim P} \left[\log \frac{p(x)}{q(x)}\right]$, we have:
    \begin{equation}
    \begin{split}
    V(G, D_G^*) &amp;= \mathbb{E}_{x \sim p_{\text{data}}} \left[\log \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)}\right] + \mathbb{E}_{x \sim p_g} \left[\log \frac{p_g(x)}{p_{\text{data}}(x) + p_g(x)}\right] \\
    &amp;= -\log4 + \text{KL}\left(p_{\text{data}} \| \frac{p_\text{data} + p_g}{2}\right) + \text{KL}\left(p_g \| \frac{p_{\text{data}} + p_g}{2}\right) \\
    &amp;= -\log4 + 2 \cdot \text{JSD}(p_{\text{data}} \| p_g) \\
    &amp; \geq -\log4
    \end{split}
    \end{equation}

    The equality holds if and only if $p_{\text{data}} = p_g$.
\end{question}

\section{Adversarial Attacks}

\begin{question}[Principle of Generating Adversarial Attacks]
    \begin{equation}
        \max_{\left\|x_{\text{adv}}-x\right\|_{\infty} \leq \epsilon} \mathcal{L}(C(x_{\text{adv}}), y)
    \end{equation}

    where $C$ is the composition of $h$ and $f$.
\end{question}

\begin{question}[Different Solvers] to optimize the adversarial attack.
    \begin{itemize}
        \item \textbf{Zero-Order Solvers} (only access to the output of NN)
        \begin{itemize}
            \item Black-box attack
        \end{itemize}
        \item \textbf{First-Order Solvers} (access to the gradient of NN)
        \begin{itemize}
            \item White-box attack
            \item Fast Gradient Sign Method (FGSM), BIM, PGD, CW attack, \dots
        \end{itemize}
        \item \textbf{Second-Order Solvers} (access to the Hessian matrix)
        \begin{itemize}
            \item White-box attack
            \item L-BFGS attack
        \end{itemize}
    \end{itemize}
\end{question}

\begin{question}[Holder Inequality]
    For any $p, q \geq 1$ such that $\frac{1}{p} + \frac{1}{q} = 1$,
    \begin{equation} \label{eq:holder-inequality}
        \left\|x\right\|_p \cdot \left\|y\right\|_q \geq \left\langle x, y \right\rangle
    \end{equation}
    where $\left\langle x, y \right\rangle$ is the inner product.

    $\| \cdot \|_p$ and $\| \cdot \|_q$ are also known as dual norms.
    \begin{itemize}
        \item $\| \cdot \|_2$ is self-dual.
        \item $\| \cdot \|_\infty$ and $\| \cdot \|_1$ are dual norms.
    \end{itemize}
\end{question}

\begin{question}[FGSM -- Fast Gradient Sign Method]
    White-box and non-targeted (maximize the loss w.r.t. the true label).

    Do linear expansion at $x$:
    \begin{equation}
        \mathcal{L}(C(x + \delta), y) \approx \underbrace{\mathcal{L}(C(x), y)}_{\text{constant}} + \nabla_x \mathcal{L}(C(x), y) \cdot \delta
    \end{equation}

    The problem reduces to:
    \begin{equation}
        \max_{\left\|\delta\right\|_{\infty} \leq \epsilon} \nabla_x \mathcal{L}(C(x), y) \cdot \delta
    \end{equation}

    Because of holder inequality \eqref{eq:holder-inequality}, we have:
    \begin{equation}
        \nabla_x \mathcal{L}(C(x), y) \cdot \delta \leq \left\|\delta\right\|_{\infty} \cdot \left\|\nabla_x \mathcal{L}(C(x), y)\right\|_1
        \leq \epsilon \cdot \left\|\nabla_x \mathcal{L}(C(x), y)\right\|_1
    \end{equation}

    Thus, the adversarial example is generated by:

    \begin{equation}
        x_{\text{adv}} = x + \epsilon \cdot \text{sign}(\nabla_x \mathcal{L}(C(x), y))
    \end{equation}

    where $\epsilon$ is the perturbation size.
\end{question}

\begin{question}[BIM -- Basic Iterative Method]
    BIM is an iterative version of FGSM.
    \begin{itemize}
        \item Initialize $x^{(0)} = x$.
        \item For $k = 1, 2, \dots, K$:
        \begin{equation}
            x^{(k)} = x^{(k-1)} + \gamma \cdot \text{sign}(\nabla_x \mathcal{L}(C(x^{(k-1)}), y))
        \end{equation}
    \end{itemize}

    Issues:
    \begin{itemize}
        \item By repeating, the pertubation size $\epsilon$ will become larger.
        \item For a pre-defined $\epsilon$, $x^{(k)}$ may not satisfy $\|x^{(k)} - x\|_\infty \leq \epsilon$.
    \end{itemize}
\end{question}

\begin{question}[PGD -- Projected Gradient Descent]
    To resolve the issue of BIM, PGD involves a truncation operation:
    \begin{itemize}
        \item Initialize $x^{(0)} = x + \delta, \text{ where } \delta \in (-\epsilon, \epsilon)$.
        \item For $k = 1, 2, \dots, K$:
        \begin{equation}
            x^{(k)} = \text{clip}_{(-\epsilon, \epsilon)}(x^{(k-1)} + \gamma \cdot \text{sign}(\nabla_x \mathcal{L}(C(x^{(k-1)}), y)))
        \end{equation}
    \end{itemize}

    where $\text{clip}_{(-\epsilon, \epsilon)}(x)$ projects $x$ back to the $\ell_\infty$ ball of radius $\epsilon$ around $x$.
\end{question}

\begin{question}[Targeted PGD Attack]
    Objective:

    \begin{itemize}
        \item \textbf{Untargeted}: \begin{equation}
            \max_{\left\|\delta\right\|_{\infty} \leq \epsilon} \mathcal{L}(C(x + \delta), y_{\text{true}})
        \end{equation}
        \item \textbf{Targeted}: \begin{equation}
            \begingroup\color{red}\min_{\left\|\delta\right\|_{\infty} \leq \epsilon}\endgroup \mathcal{L}(C(x + \delta), \begingroup\color{red}y_{\text{target}}\endgroup)
        \end{equation}
    \end{itemize}
\end{question}

\section{Adversarial Robustness}

\begin{question}[Defense Mechanisms]
    Categorized into two types:
    \begin{itemize}
        \item \textbf{Gradient Masking}: hide the gradients and make first-order attacks fail
        \begin{itemize}
            \item \textbf{Shasttered Gradients}
            By applying a non-smooth or non-differentiable preprocessor $g$ to the inputs,
            and then training a DNN model $f$ on the preprocessed inputs $g(x)$.

            \item \textbf{Stochastic/Randomized Gradients}
            Apply some form of randomization of the DNN model.
            E.g. train a set of classifiers and during the testing phase randomly select one classifier to predict the labels.
        \end{itemize}
        \item \textbf{Adversarial Training}: 
        \begin{equation}
            \min_{C} \mathbb{E}_{(x, y) \sim \mathcal{D}^n} \left[ \max_{\left\|\delta\right\|_{\infty} \leq \epsilon} \mathcal{L}(C(x + \delta), y) \right]
        \end{equation}
    \end{itemize}
\end{question}

\begin{question}[Trade-Off between Natural and Robust Error]
    \begin{equation}
    \min_f R_{\text{nat}}(f) + R_{\text{rob}}(f) / \lambda
    \end{equation}

    \begin{equation}
        \begin{split}
        R_{\text{nat}}(f) &amp;\coloneq \Pr_{x,y \sim \mathcal{D}} \{f(x) y \leq 0\} \\
        &amp;= \mathbb{E}_{(x, y) \sim \mathcal{D}} \left[ \mathbb{I}(f(x) y \leq 0) \right] \\
        \end{split}
    \end{equation}
    \begin{equation}
        \begin{split}
        R_{\text{rob}}(f) &amp;\coloneq \Pr_{x,y \sim \mathcal{D}} \{\exists \delta \in B_\epsilon(x) \text{ s.t. } f(x + \delta) y \leq 0\} \\
        &amp;= \mathbb{E}_{(x, y) \sim \mathcal{D}} \left[ \max_{\left\|\delta\right\|_{\infty} \leq \epsilon} \mathbb{I}(f(x + \delta) y \leq 0) \right] \\
        \end{split}
    \end{equation}

    Approximate by a differentiable surrogate loss $\Phi$:
    \begin{equation}
        R_{\text{nat}}(f) \approx \mathbb{E}_{(x, y) \sim \mathcal{D}} \left[ \Phi(f(x) y) \right]
    \end{equation}
\end{question}

\begin{question}[TRADES]
    \begin{equation}
        \min_f \underbrace{\left[ \underbrace{\mathbb{E}_{(x, y) \sim \mathcal{D}} \left[ \Phi(f(x) y) \right]}_{\text{minimize diff btw } f(x) \text{ and } y \text{ for accuracy}} + \underbrace{\mathbb{E}_{(x, y) \sim \mathcal{D}} \left[ \max_{\left\|\delta\right\|_{\infty} \leq \epsilon} \Phi(f(x + \delta) f(x)) \right]}_{\text{minimize diff btw }f(x) \text{ and } f(x+\delta){ for robustness}} / \lambda \right]}_{\text{TRADES Loss}}
    \end{equation}
\end{question}

\section{Self-Supervised Learning}

\begin{question}[Contrastive Learning]
    Loss:

    \begin{equation}
        \max_\Theta \Pr_1 = \frac{\exp(z_1)}{\sum_j \exp(z_j)}
    \end{equation}
\end{question}

\end{document}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cs-848-advanced-topics-in-database-algorithmic-aspects-of-database-query-processing"><a class="header" href="#cs-848-advanced-topics-in-database-algorithmic-aspects-of-database-query-processing">CS 848: Advanced Topics in Database: Algorithmic Aspects of Database Query Processing</a></h1>
<blockquote>
<p>Fall 25</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h1 id="notes-for-foundations-of-databases"><a class="header" href="#notes-for-foundations-of-databases">Notes for <em>Foundations of Databases</em></a></h1>
<p><a href="http://webdam.inria.fr/Alice/">Foundations of Databases (The Alice Book)</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-relational-model"><a class="header" href="#the-relational-model">The Relational Model</a></h1>
<!-- prettier-ignore-start -->
<blockquote>
<p><em>Mathjax</em> may have <a href="https://meta.stackexchange.com/questions/384924/i-think-there-is-a-mathjax-bug-for-mathcal-typesetting-on-some-platforms">issues</a> to display math symbols in particular styles, such as \(\mathcal{A}\).<br />
You can try to mitigate this by changing the <em>Math Renderer</em> to <em>Common HTML</em> (right click on any math expressions):
<img src="notes/cs848/foundations/../../../mathjax.png" alt="mathjax" />
\( \newcommand{\att}{\textbf{att}} \)
\( \newcommand{\attTotalOrder}{\leq_{\att}} \)
\( \newcommand{\dom}{\textbf{dom}} \)
\( \newcommand{\Dom}{\textit{Dom}} \)
\( \newcommand{\relname}{\textbf{relname}} \)
\( \newcommand{\sort}{\textit{sort}} \)
\( \newcommand{\arity}{\textit{arity}} \)
\( \newcommand{\finPowerSet}{\mathcal{P}^{\text{fin}}} \)
\( \newcommand{\dbschema}[1]{\textbf{#1}} \)
\( \newcommand{\dbinst}[1]{\textbf{#1}} \)
\( \newcommand{\rel}[1]{\textit{#1}} \)
\( \newcommand{\attname}[1]{\textit{#1}} \)
\( \newcommand{\varSet}{\textbf{var}} \)</p>
</blockquote>
<!-- prettier-ignore-end -->
<h2 id="informal-terminology"><a class="header" href="#informal-terminology">Informal Terminology</a></h2>
<ul>
<li><em>Relation</em>: table
<ul>
<li><em>Relation Name</em>: name of the table</li>
</ul>
</li>
<li><em>Attribute</em>: column name</li>
<li><em>Tuple/Record</em>: line in the table</li>
<li><em>Domain</em>: set of constants that entries of tuples can take</li>
<li><em>Database Schema</em>: specifying the structure of the database</li>
<li><em>Database Instance</em>: specifying the actual content in the database</li>
</ul>
<h2 id="formal-definitions"><a class="header" href="#formal-definitions">Formal Definitions</a></h2>
<ul>
<li>\(\att\): a countably infinite set of <em>attributes</em>
<ul>
<li>assume \(\att\) is fixed</li>
</ul>
</li>
<li>\(\attTotalOrder\): a total order on \(\att\)
<ul>
<li>the elements of a set of attributes \(U\) are written according to \(\attTotalOrder\) unless otherwise specified</li>
</ul>
</li>
<li>\(\dom\): a countably infinite set of <em>domains</em> (disjoint from \(\att\))
<ul>
<li>assume \(\dom\) is fixed</li>
<li>a <em>constant</em> is an element of \(\dom\)</li>
<li>for most cases, the same domain of values is used for all attributes;
<ul>
<li>otherwise, assume a mapping \(\Dom\) on \(\att\), where \(\Dom(A)\) is a set called the domain of attribute \(A\)</li>
</ul>
</li>
</ul>
</li>
<li>\(\relname\): a countably infinite set of <em>relation names</em> (disjoint from \(\att\) and \(\dom\))</li>
<li>\(\sort\): a function from \(\relname\) to \(\finPowerSet(\att)\) (the finitary powerset of \(\att\))
<ul>
<li>\(\sort^{-1}(U)\) is inifinite for each (possibly empty) finite set of attributes \(U\)
<ul>
<li>which allows multiple relations to have the same set of attributes</li>
</ul>
</li>
<li>\(\sort(R)\) is called the \(\sort\) of a relation name \(R\)</li>
<li>\(\arity(R) = |\sort(R)|\): the \(\arity\) of relation name \(R\)</li>
</ul>
</li>
<li>\(R\): a relation name or a <em>relation schema</em>
<ul>
<li>Alternative notations:
<ul>
<li>\(R[U]\): indicating \(\sort(R) = U\)</li>
<li>\(R[n]\): indicating \(\arity(R) = n\)</li>
</ul>
</li>
</ul>
</li>
<li>\(\dbschema{R}\): a <em>database schema</em>
<ul>
<li>a nonempty finite set of relation names</li>
<li>might be written as \(\dbschema{R} = \{R_1[U_1], \ldots, R_n[U_n]\}\)</li>
</ul>
</li>
</ul>
<h2 id="examples"><a class="header" href="#examples">Examples</a></h2>
<p>Table <em>Movies</em></p>
<div class="table-wrapper"><table><thead><tr><th>Title</th><th>Director</th><th>Actor</th></tr></thead><tbody>
<tr><td>A</td><td>X</td><td>Y</td></tr>
</tbody></table>
</div>
<p>Table <em>Location</em></p>
<div class="table-wrapper"><table><thead><tr><th>Theater</th><th>Address</th><th>Phone</th></tr></thead><tbody>
<tr><td>T1</td><td>Addr1</td><td>P1</td></tr>
</tbody></table>
</div>
<p>Table <em>Pariscope</em></p>
<div class="table-wrapper"><table><thead><tr><th>Theater</th><th>Title</th><th>Schedule</th></tr></thead><tbody>
<tr><td>T1</td><td>A</td><td>9:00</td></tr>
</tbody></table>
</div>
<ul>
<li>The database schema \(\dbschema{CINEMA} = \{ \rel{Movies}, \rel{Location}, \rel{Pariscope} \}\)</li>
<li>The sorts of the relation names
<ul>
<li>\(\sort(\rel{Movies}) = \{ \attname{Title}, \attname{Director}, \attname{Actor} \}\)</li>
<li>\(\sort(\rel{Location}) = \{ \attname{Theater}, \attname{Address}, \attname{Phone} \}\)</li>
<li>\(\sort(\rel{Pariscope}) = \{ \attname{Theater}, \attname{Title}, \attname{Schedule} \}\)</li>
</ul>
</li>
</ul>
<h2 id="named-vs-unnamed-attributestuples"><a class="header" href="#named-vs-unnamed-attributestuples">Named v.s. Unnamed Attributes/Tuples</a></h2>
<h3 id="named-perspective"><a class="header" href="#named-perspective">Named Perspective</a></h3>
<p>E.g. \( \langle A:5, B:3 \rangle \)</p>
<p>a <em>tuple</em> over a finite set of attributes \(U\) (or over a relation schema \(R[U]\))
is a total mapping (viewed as a function) \(u\) from \(U\) to \(\dom\).</p>
<ul>
<li>\(u(U)\): \(u\) is a tuple over \(U\)</li>
<li>\(u(A)\): the value of \(u\) on an attribute \(A\) in \(U\) (\(A \in U\))</li>
<li>\(u[V] = u \vert_V\): the restriction of \(u\) to a subset \(V \subseteq U\), i.e.,
\(u[V]\) denotes the tuple \(v\) over \(V\) such that \(v(A) = u(A)\) for all \(A \in V\)</li>
</ul>
<h3 id="unnamed-perspective"><a class="header" href="#unnamed-perspective">Unnamed Perspective</a></h3>
<p>E.g. \( \langle 5, 3 \rangle \)</p>
<p>a <em>tuple</em> is an ordered <em>n</em>-tuple (\(n \geq 0\)) of constants (i.e., an element of the Cartesian product \(\dom^n\))</p>
<ul>
<li>\(u(i)\): the \(i\)-th coordinate of \(u\)</li>
</ul>
<h3 id="correspondence"><a class="header" href="#correspondence">Correspondence</a></h3>
<p>Because of the total order \(\attTotalOrder\), a tuple \(\langle A_1:a_1, A_2:a_2 \rangle\) (defined as a function)
can be viewed as an ordered tuple with \((A_1:a_1)\) as a first component and \((A_2:a_2)\) as a second component.
Ignoring the names, this tuple can be viewed as the ordered tuple \(\langle a_1, a_2 \rangle\).</p>
<p>Conversely, the ordered tuple \(t = \langle a_1, a_2 \rangle\) can be viewed as a function over the set of integers \(\{1, 2\}\)
with \(t(i) = a_i\) for each \(i\).</p>
<h2 id="conventional-vs-logic-programming-relational-model"><a class="header" href="#conventional-vs-logic-programming-relational-model">Conventional v.s. Logic Programming Relational Model</a></h2>
<h3 id="conventional-perspective"><a class="header" href="#conventional-perspective">Conventional Perspective</a></h3>
<p>a <em>relation (instance)</em> over a relation schema \(\rel{R}[U]\) is a finite set of tuples \(I\) with sort \(U\).</p>
<p>a <em>database instance</em> of database schema \(\dbschema{R}\) is a mapping \(\dbinst{I}\) with domain \(\dbschema{R}\),
such that \(\dbinst{I}(\rel{R})\) is a relation over \(\rel{R}\) for each \(\rel{R} \in \dbschema{R}\).</p>
<h3 id="logic-programming-perspective"><a class="header" href="#logic-programming-perspective">Logic Programming Perspective</a></h3>
<p>This perspective is used primarily with the ordered-tuple perspective on tuples.</p>
<p>A <em>fact</em> over \(\rel{R}\) is an expression of the form \(\rel{R}(a_1, \ldots, a_n)\),
where \(a_i \in \dom\) for \(i \in [1, n]\).<br />
If \(u = \langle a_1, \ldots, a_n \rangle\), we sometimes write \(\rel{R}(u)\) for \(\rel{R}(a_1, \ldots, a_n)\).</p>
<p>a <em>relation (instance)</em> over a relation schema \(\rel{R}\) is a finite set of facts over \(\rel{R}\).</p>
<p>a <em>database instance</em> of database schema \(\dbschema{R}\) is a finite set \(\dbinst{I}\) that is
the union of relation instances over \(\rel{R}\) for all \(\rel{R} \in \dbschema{R}\).</p>
<h3 id="examples-1"><a class="header" href="#examples-1">Examples</a></h3>
<p>Assume \(\sort(R) = AB, \sort(S) = A\).</p>
<h4 id="named-and-conventional"><a class="header" href="#named-and-conventional">Named and Conventional</a></h4>
<p>\[
\begin{split}
I(R) = \{ f_1, f_2, f_3 \} \quad &amp;&amp; \\
&amp; f_1(A) = a &amp;\quad f_1(B) = b \\
&amp; f_2(A) = c &amp;\quad f_2(B) = b \\
&amp; f_3(A) = a &amp;\quad f_3(B) = a \\
I(S) = \{g\} \quad &amp;&amp; \\
&amp; g(A) = d &amp;
\end{split}
\]</p>
<h4 id="unnamed-and-conventional"><a class="header" href="#unnamed-and-conventional">Unnamed and Conventional</a></h4>
<p>\[
\begin{split}
I(R) = \{ \langle a, b \rangle, \langle c, b \rangle, \langle a, a \rangle \} \quad &amp;&amp; \\
I(S) = \{ \langle d \rangle \} \quad &amp;&amp;
\end{split}
\]</p>
<h4 id="named-and-logic-programming"><a class="header" href="#named-and-logic-programming">Named and Logic Programming</a></h4>
<p>\[
\{ R(A:a, B:b), R(A:c, B:b), R(A:a, B:a), S(A:d) \}
\]</p>
<h4 id="unnamed-and-logic-programming"><a class="header" href="#unnamed-and-logic-programming">Unnamed and Logic Programming</a></h4>
<p>\[
\{ R(a, b), R(c, b), R(a, a), S(d) \}
\]</p>
<h2 id="variables"><a class="header" href="#variables">Variables</a></h2>
<p>an infinite set of <em>variables</em> \(\varSet\) will be used to range over elements of \(\dom\).</p>
<!-- prettier-ignore-start -->
<ul>
<li>a <em>free tuple</em> over \(U\) or \(\rel{R}(U)\) is a function \(u\) from \(U\) to \(\dom \cup \varSet\)</li>
<li>an <em>atom</em> over \(\rel{R}\) is an expression of the form \(\rel{R}(e_1, \ldots, e_n)\),
where \(n = \arity(\rel{R})\) and each <em>term</em> \(e_i \in \dom \cup \varSet\)</li>
<li>a <em>ground atom</em> is an atom with no variables, i.e., a <em>fact</em> (see <a href="notes/cs848/foundations/01.the-relation-model.html#logic-programming-perspective">Logic Programming Perspective</a>)</li>
</ul>
<!-- prettier-ignore-end -->
<h2 id="notations"><a class="header" href="#notations">Notations</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Object</th><th>Notation</th></tr></thead><tbody>
<tr><td>Constants</td><td>\(a, b, c\)</td></tr>
<tr><td>Variables</td><td>\(x, y\)</td></tr>
<tr><td>Sets of Variables</td><td>\(X, Y\)</td></tr>
<tr><td>Terms</td><td>\(e\)</td></tr>
<tr><td>Attributes</td><td>\(A, B, C\)</td></tr>
<tr><td>Sets of Attributes</td><td>\(U, V, W\)</td></tr>
<tr><td>Relation Names</td><td>\(\rel{R}, \rel{S}; \rel{R}[U], \rel{S}[V] \)</td></tr>
<tr><td>Database Schemas</td><td>\(\dbschema{R}, \dbschema{S} \)</td></tr>
<tr><td>Tuples</td><td>\(t, s\)</td></tr>
<tr><td>Free Tuples</td><td>\(u, v, w\)</td></tr>
<tr><td>Facts</td><td>\(\rel{R}(a_1, \ldots, a_n), R(t)\)</td></tr>
<tr><td>Atoms</td><td>\(\rel{R}(e_1, \ldots, e_n), R(u)\)</td></tr>
<tr><td>Relation Instances</td><td>\(I, J\)</td></tr>
<tr><td>Database Instances</td><td>\(\dbinst{I}, \dbinst{J} \)</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="conjunctive-queries"><a class="header" href="#conjunctive-queries">Conjunctive Queries</a></h1>
<!-- prettier-ignore-start -->
<blockquote>
<p><em>Mathjax</em> may have <a href="https://meta.stackexchange.com/questions/384924/i-think-there-is-a-mathjax-bug-for-mathcal-typesetting-on-some-platforms">issues</a> to display math symbols in particular styles, such as \(\mathcal{A}\).<br />
You can try to mitigate this by changing the <em>Math Renderer</em> to <em>Common HTML</em> (right click on any math expressions):
<img src="notes/cs848/foundations/../../../mathjax.png" alt="mathjax" />
\( \newcommand{\att}{\textbf{att}} \)
\( \newcommand{\attTotalOrder}{\leq_{\att}} \)
\( \newcommand{\dom}{\textbf{dom}} \)
\( \newcommand{\Dom}{\textit{Dom}} \)
\( \newcommand{\relname}{\textbf{relname}} \)
\( \newcommand{\sort}{\textit{sort}} \)
\( \newcommand{\arity}{\textit{arity}} \)
\( \newcommand{\finPowerSet}{\mathcal{P}^{\text{fin}}} \)
\( \newcommand{\dbschema}[1]{\textbf{#1}} \)
\( \newcommand{\dbinst}[1]{\textbf{#1}} \)
\( \newcommand{\rel}[1]{\textit{#1}} \)
\( \newcommand{\attname}[1]{\textit{#1}} \)
\( \newcommand{\varSet}{\textbf{var}} \)
\( \newcommand{\ans}{\textit{ans}} \)
\( \newcommand{\var}{\textit{var}} \)
\( \newcommand{\adom}{\textit{adom}} \)
\( \newcommand{\tableau}{\textbf{T}} \)
\( \newcommand{\free}{\textit{free}} \)
\( \newcommand{\body}{\text{body}} \)</p>
</blockquote>
<!-- prettier-ignore-end -->
<p>a query (mapping) is <em>from</em> (or <em>over</em>) its input schema and <em>to</em> its output schema.</p>
<!-- prettier-ignore-start -->
<ul>
<li><em>query</em>: a syntactic object</li>
<li><em>query mapping</em>: a function defined by a query interpreted under a specified semantics
<ul>
<li>its domain: the family of all instances of an input schema</li>
<li>its range: the family of instances of an output schema</li>
<li>we often blur query and query mapping when the meaning is clear from context</li>
</ul>
</li>
<li><em>input schema</em>: a specified relation or database schema</li>
<li><em>output schema</em>: a relation schema or database schema
<ul>
<li>For a relation schema, the relation name may be specified as part of the query syntax or by the context</li>
</ul>
</li>
<li>\(q_1 \equiv q_2\) denotes two queries \(q_1\) and \(q_2\) over \(\dbschema{R}\) are <em>equivalent</em>,
i.e., they have the same output schema and \(q_1(\dbinst{I}) = q_2(\dbinst{I})\) for each instance \(\dbinst{I}\) over \(\dbschema{R}\).</li>
</ul>
<!-- prettier-ignore-end -->
<h2 id="logic-based-perspective"><a class="header" href="#logic-based-perspective">Logic-Based Perspective</a></h2>
<p>Three versions of conjunctive queries:</p>
<ol>
<li>Rule-Based Conjunctive Queries</li>
<li>Tableau Queries</li>
<li>Conjunctive Calculus</li>
</ol>
<h3 id="rule-based-conjunctive-queries"><a class="header" href="#rule-based-conjunctive-queries">Rule-Based Conjunctive Queries</a></h3>
<h4 id="definition"><a class="header" href="#definition">Definition</a></h4>
<!-- prettier-ignore-start -->
<p>A <em>rule-based conjunctive query</em> (or often more simply called <em>rules</em>) \(q\) over a relation schema \(\dbschema{R}\) is an expression of the form
\[
\ans(u) \leftarrow \rel{R}_1(u_1), \ldots, \rel{R}_n(u_n)
\]
where \(n \geq 0\), \(\rel{R}_1, \ldots, \rel{R}_n\) are relation names in \(\dbschema{R}\);
\(\ans\) is a relation name not in \(\dbschema{R}\);
and \(u, u_1, \ldots, u_n\) are free tuples (i.e., may use either variables or constants).</p>
<ul>
<li>\(\var(q)\): the set of variables occurring in \(q\).</li>
<li><em>body</em>: \(\rel{R}_1(u_1), \ldots, \rel{R}_n(u_n)\)</li>
<li><em>head</em>: \(\ans(u)\)</li>
<li><em>range restricted</em>: each variable occurring in the head also occurs in the body
<ul>
<li>all conjunctive queries considered here are range restricted</li>
</ul>
</li>
<li><em>valuation</em>: a valuation \(v\) over \(V\), a finite subset of \(\varSet\), is a total function \(v\) from \(V\) to \(\dom\) (of constants)
<ul>
<li>extended to be identity on \(\dom\) (so that the domain can contain both variables and constants)</li>
<li>extended to map free tuples to tuples (so that the domain/range can be in the tuple form)</li>
</ul>
</li>
</ul>
<!-- prettier-ignore-end -->
<h4 id="semantics"><a class="header" href="#semantics">Semantics</a></h4>
<p>Let \(q\) be the query, and let \(\dbinst{I}\) be a database instance of schema \(\dbschema{R}\).
The <em>image</em> of \(\dbinst{I}\) under \(q\) is:</p>
<!-- prettier-ignore-start -->
<p>\[
q(\dbinst{I}) = \{ v(u) \mid v \text{ is a valuation over } \var(q) \text{ and } v(u_i) \in \dbinst{I}(\rel{R}_i) \text{ for each } i \in [1, n] \}
\]</p>
<ul>
<li><em>active domain</em>
<ul>
<li>of a database instance \(\dbinst{I}\), denoted \(\adom(\dbinst{I})\), is the set of constants that occur in \(\dbinst{I}\)</li>
<li>of a relation instance \(I\), denoted \(\adom(I)\), is the set of constants that occur in \(I\)</li>
<li>of a query \(q\), denoted \(\adom(q)\), is the set of constants that occur in \(q\)</li>
<li>\(\adom(q, \dbinst{I})\) is an abbreviation for \(\adom(q) \cup \adom(\dbinst{I})\)
<ul>
<li>\(\adom(q(\dbinst{I})) \subseteq \adom(q, \dbinst{I})\)</li>
</ul>
</li>
</ul>
</li>
<li><em>extensional</em> relations: relations in the body of the query, i.e., \(\rel{R}_1, \ldots, \rel{R}_n\)
<ul>
<li>because they are known/provided by the input instance \(\dbinst{I}\)</li>
</ul>
</li>
<li><em>intensional</em> relation: the relation in the head of the query, i.e., \(\ans\)
<ul>
<li>because it is not stored and its value is computed on request by the query</li>
</ul>
</li>
<li><em>extensional database (edb)</em>: a database instance associated with the extensional relations</li>
<li><em>intensional database (idb)</em>: the rule itself</li>
<li><em>idb relation</em>: the relation defined by the idb</li>
</ul>
<!-- prettier-ignore-end -->
<h4 id="properties"><a class="header" href="#properties">Properties</a></h4>
<p>Conjunctive queries are:</p>
<ul>
<li><em>monotonic</em>: a query \(q\) over \(\dbschema{R}\) is monotonic if for each \(\dbinst{I}, \dbinst{J}\) over \(\dbschema{R}\),
\(\dbinst{I} \subseteq \dbinst{J} \implies q(\dbinst{I}) \subseteq q(\dbinst{J})\)</li>
<li><em>satisfiable</em>: a query \(q\) is satisfiable if there exists a database instance \(\dbinst{I}\) such that \(q(\dbinst{I}) \neq \emptyset\)</li>
</ul>
<h3 id="tableau-queries"><a class="header" href="#tableau-queries">Tableau Queries</a></h3>
<p>A <em>tableau query</em> is simply a pair \((\tableau, u)\) where \(\tableau\) is a tableau
and each variable in \(u\) also occurs in \(\tableau\).</p>
<p>This is closest to the visual form provided by Query-By-Example (QBE).</p>
<ul>
<li><em>summary</em>: the free tuple \(u\) representing the tuples included in the answer to the query</li>
<li><em>embedding</em>: a valuation \(v\) for the variables occurring in \(\tableau\) such that \(v(\tableau) \subseteq \dbinst{I}\)
<ul>
<li>the output of \((\tableau, u)\) on \(\dbinst{I}\) consists of all tuples \(v(u)\) for each embedding \(v\) of \(\tableau\) into \(\dbinst{I}\)</li>
</ul>
</li>
<li><em>typed</em>: a tableau query \(q = (\tableau, u)\) under the named perspective, where \(\tableau\) is
over relation schema \(R\) and \(\sort(u) \subseteq \sort(R)\), is typed if no variable of \(\tableau\)
is associated with two distinct attributes in \(q\)</li>
</ul>
<h4 id="examples-2"><a class="header" href="#examples-2">Examples</a></h4>
<p>Table <em>Movies</em></p>
<div class="table-wrapper"><table><thead><tr><th>Title</th><th>Director</th><th>Actor</th></tr></thead><tbody>
<tr><td>\(x_{ti}\)</td><td>“Bergman”</td><td>\(x_{ac}\)</td></tr>
</tbody></table>
</div>
<p>Table <em>Location</em></p>
<div class="table-wrapper"><table><thead><tr><th>Theater</th><th>Address</th><th>Phone</th></tr></thead><tbody>
<tr><td>\(x_{th}\)</td><td>\(x_{ad}\)</td><td>\(x_p\)</td></tr>
</tbody></table>
</div>
<p>Table <em>Pariscope</em></p>
<div class="table-wrapper"><table><thead><tr><th>Theater</th><th>Title</th><th>Schedule</th></tr></thead><tbody>
<tr><td>\(x_{th}\)</td><td>\(x_{ti}\)</td><td>\(x_{s}\)</td></tr>
</tbody></table>
</div>
<p>The above tableau query is typed because each variable is associated with only one attribute:</p>
<ul>
<li>\(x_{ti}\): \(\attname{Title}\)</li>
<li>\(x_{ac}\): \(\attname{Actor}\)</li>
<li>\(x_{th}\): \(\attname{Theater}\)</li>
<li>\(x_{ad}\): \(\attname{Address}\)</li>
<li>\(x_p\): \(\attname{Phone}\)</li>
<li>\(x_{s}\): \(\attname{Schedule}\)</li>
</ul>
<p>However, the following tableau query is untyped:</p>
<p>Table <em>Movies</em></p>
<div class="table-wrapper"><table><thead><tr><th>Title</th><th>Director</th><th>Actor</th></tr></thead><tbody>
<tr><td>\(x_{ti}\)</td><td>\(x_{ac}\)</td><td>\(x_{ac}\)</td></tr>
</tbody></table>
</div>
<p>Because \(x_{ac}\) is associated with both \(\attname{Director}\) and \(\attname{Actor}\).</p>
<h3 id="conjunctive-calculus"><a class="header" href="#conjunctive-calculus">Conjunctive Calculus</a></h3>
<p>The conjunctive query
\[
\ans(u) \leftarrow \rel{R}_1(u_1), \ldots, \rel{R}_n(u_n)
\]</p>
<p>can be expressed as the following conjunctive calculus query that has the same semantics:
\[
\left\{ e_1, \ldots, e_m \vert \exists x_1, \ldots, x_k \left( \rel{R}(u_1) \wedge \ldots \wedge \rel{R}(u_n) \right) \right\}
\]
where \(x_1, \ldots, x_k\) are all the variables occurring in the body and not the head.</p>
<h4 id="conjunctive-calculus-formula"><a class="header" href="#conjunctive-calculus-formula">Conjunctive Calculus Formula</a></h4>
<p>Let \(\dbschema{R}\) be a relation schema.
A <em>(well-formed) formula</em> over \(\dbschema{R}\) for the conjunctive calculus is an expression having <strong>one of</strong> the following forms:</p>
<ol>
<li>an atom over \(\dbschema{R}\);</li>
<li>\(\varphi \wedge \psi \), where \(\varphi\) and \(\psi\) are formulas over \(\dbschema{R}\); or</li>
<li>\(\exists x \varphi\), where \(x\) is a variable and \(\varphi\) is a formula over \(\dbschema{R}\).</li>
</ol>
<p>An occurrence of a variable \(x\) in formula \(\varphi\) is <em>free</em> if:</p>
<ol>
<li>\(\varphi\) is an atom; or</li>
<li>\(\varphi = (\psi \wedge \xi)\) and the occurrence of \(x\) is free in \(\psi\) or \(\xi\); or</li>
<li>\(\varphi = \exists y \psi\), \(x \neq y\), and the occurrence of \(x\) is free in \(\psi\).</li>
</ol>
<p>\(\free(\varphi)\): the set of free variables in \(\varphi\).</p>
<p>An occurrence of a variable that is not free is <em>bound</em>.</p>
<h4 id="conjunctive-calculus-query"><a class="header" href="#conjunctive-calculus-query">Conjunctive Calculus Query</a></h4>
<p>A <em>conjunctive calculus query</em> over database schema \(\dbschema{R}\) is an expression of the form
\[
\{ e_1, \ldots, e_m \mid \varphi \}
\]
where</p>
<ul>
<li>\(\varphi\) is a conjunctive calculus formula,</li>
<li>\(\langle e_1, \ldots, e_m \rangle\) is a free tuple, and</li>
<li>the set of variables occurring in \(\langle e_1, \ldots, e_m \rangle\) is exactly \(\free(\varphi)\).</li>
</ul>
<p>For named perspective, the above query can be written as:
\[
\{ \langle e_1, \ldots, e_m \rangle : A_1, \ldots, A_m \mid \varphi \}
\]</p>
<blockquote>
<p>Note: In the previous chapter, a named tuple was usually denoted as:</p>
<p>\[ \langle A_1:a_1, \ldots, A_m:a_m \rangle \]</p>
<p>But here we denote the named tuple as:</p>
<p>\[ \langle e_1, \ldots, e_m \rangle : A_1, \ldots, A_m \]</p>
<p>Not sure which one is better or whether the author did this intentionally.</p>
</blockquote>
<h4 id="semantics-1"><a class="header" href="#semantics-1">Semantics</a></h4>
<h5 id="valuation"><a class="header" href="#valuation">Valuation</a></h5>
<p>A <em>valuation</em> over \(V \subset \varSet \) is a total function \(v\) from \(V\) to \(\dom\),
which can be viewed as a syntactic expression of the form:
\[
\{ x_1/a_1, \ldots, x_n/a_n \}
\]
where</p>
<ul>
<li>\(x_1, \ldots, x_n\) is a listing of \(V\),</li>
<li>\(a_i = v(x_i)\) for each \(i \in [1, n]\).</li>
</ul>
<h5 id="interpretation-as-a-set"><a class="header" href="#interpretation-as-a-set">Interpretation as a Set</a></h5>
<p>If \(x \not \in V\), and \(c \in \dom\),
then \(v \cup \{ x/c \}\) is the valuation over \(V \cup \{ x \}\)
that agrees with \(v\) on \(V\) and maps \(x\) to \(c\).</p>
<h5 id="satisfaction"><a class="header" href="#satisfaction">Satisfaction</a></h5>
<p>Let \(\dbschema{R}\) be a database schema, \(\varphi\) a conjunctive calculus formula over \(\dbschema{R}\),
and \(v\) a valuation over \(\free(\varphi)\).
Then \(\dbinst{I} \models \varphi[v]\), if</p>
<ol>
<li>\(\varphi = \rel{R}(u)\) is an atom and \(v(u) \in \dbinst{I}(\rel{R})\); or</li>
<li>\(\varphi = (\psi \wedge \xi)\) and \(\dbinst{I} \models \psi[v \vert_{\free(\psi)}]\) and \(\dbinst{I} \models \xi[v \vert_{\free(\xi)}]\); or</li>
<li>\(\varphi = \exists x \psi\) and there exists a constant \(c \in \dom\) such that
\(\dbinst{I} \models \psi[v \cup \{ x/c \}]\).</li>
</ol>
<h5 id="image"><a class="header" href="#image">Image</a></h5>
<!-- prettier-ignore-start -->
<p>Let \(q = \{ e_1, \ldots, e_m \mid \varphi \}\) be a conjunctive calculus query over \(\dbschema{R}\).
For an instance \(\dbinst{I}\) over \(\dbschema{R}\), the <em>image</em> of \(\dbinst{I}\) under \(q\) is:
\[
q(\dbinst{I}) = \{ v( \langle e_1, \ldots, e_m \rangle ) \mid v \text{ is a valuation over } \free(\varphi) \text{ and } \dbinst{I} \models \varphi[v] \}
\]</p>
<!-- prettier-ignore-end -->
<ul>
<li><em>active domain</em>
<ul>
<li>of a formula \(\varphi\), denoted \(\adom(\varphi)\), is the set of constants that occur in \(\varphi\)</li>
<li>\(\adom(\varphi, \dbinst{I})\) is an abbreviation for \(\adom(\varphi) \cup \adom(\dbinst{I})\)</li>
<li>If \(\dbinst{I} \models \varphi[v]\), then the range of \(v\) is contained in \(\adom(\dbinst{I})\)
<ul>
<li>to evaluate a conjunctive calculus query, one need only consider valuations with range constrained in \(\adom(\varphi, \dbinst{I})\),
i.e., only a finite number of them</li>
</ul>
</li>
</ul>
</li>
<li><em>equivalent</em>: conjunctive calculus formulas \(\varphi\) and \(\psi\) over \(\dbschema{R}\) are equivalent,
if
<ul>
<li>they have the same free variables and,</li>
<li>for each \(\dbinst{I}\) over \(\dbschema{R}\) and valuation \(v\) over \(\free(\varphi) = \free(\psi)\),
\(\dbinst{I} \models \varphi[v]\) if and only if \(\dbinst{I} \models \psi[v]\)</li>
</ul>
</li>
</ul>
<h4 id="normal-form"><a class="header" href="#normal-form">Normal Form</a></h4>
<p>\[
\exists x_1, \ldots, x_m \left( \rel{R}_1(u_1) \wedge \ldots \wedge \rel{R}_n(u_n) \right)
\]</p>
<p>Each conjunctive calculus query is equivalent to a conjunctive calculus query in normal form.</p>
<h3 id="expressiveness-of-query-languages"><a class="header" href="#expressiveness-of-query-languages">Expressiveness of Query Languages</a></h3>
<!-- prettier-ignore-start -->
<p>Let \(\mathcal{Q}_1\) and \(\mathcal{Q}_2\) be two query languages.</p>
<ul>
<li>\(\mathcal{Q}_1 \sqsubseteq \mathcal{Q}_2\):
\(\mathcal{Q}_1\) is <em>dominated</em> by \(\mathcal{Q}_2\)
(or \(\mathcal{Q}_2\) is <em>weaker</em> than \(\mathcal{Q}_1\)),
if for each query \(q_1 \in \mathcal{Q}_1\),
there exists a query \(q_2 \in \mathcal{Q}_2\) such that \(q_1 \equiv q_2\).</li>
<li>\(\mathcal{Q}_1 \equiv \mathcal{Q}_2\):
\(\mathcal{Q}_1\) and \(\mathcal{Q}_2\) are <em>equivalent</em>,
if \(\mathcal{Q}_1 \sqsubseteq \mathcal{Q}_2\) and \(\mathcal{Q}_2 \sqsubseteq \mathcal{Q}_1\).</li>
</ul>
<!-- prettier-ignore-end -->
<p>The rule-based conjunctive queries, tableau queries, and conjunctive calculus queries are all equivalent.</p>
<h2 id="incorporating-equality"><a class="header" href="#incorporating-equality">Incorporating Equality</a></h2>
<p>The conjunctive query</p>
<p>\[
\begin{split}
\ans(x_{th}, x_{ad}) \leftarrow &amp; \rel{Movies}(x_{ti}, \text{“Bergman”}, x_{ac}), \\
&amp; \qquad \rel{Location}(x_{th}, x_{ad}, x_p), \rel{Pariscope}(x_{th}, x_{ti}, x_s)
\end{split}
\]</p>
<p>can be expressed as:</p>
<p>\[
\begin{split}
\ans(x_{th}, x_{ad}) \leftarrow &amp; \rel{Movies}(x_{ti}, x_d, x_{ac}), x_d = \text{“Bergman”}, \\
&amp; \qquad \rel{Location}(x_{th}, x_{ad}, x_p), \rel{Pariscope}(x_{th}, x_{ti}, x_s)
\end{split}
\]</p>
<h3 id="problem-1-infinite-answers"><a class="header" href="#problem-1-infinite-answers">Problem 1: Infinite Answers</a></h3>
<p>Unrestricted rules with equality may yield infinite answers:
\[
\ans(x, y) \leftarrow \rel{R}(x), y = z
\]</p>
<p>A <em>rule-based conjunctive query with equality</em> is a <em>range-restricted</em> rule-based conjunctive query with equality.</p>
<h3 id="problem-2-unsatisfiable-queries"><a class="header" href="#problem-2-unsatisfiable-queries">Problem 2: Unsatisfiable Queries</a></h3>
<p>Consider the following query:
\[
\ans(x) \leftarrow \rel{R}(x), x = a, x = b
\]
where \(\rel{R}\) is a unary relation and \(a, b \in \dom\) with \(a \neq b\).</p>
<p>Each satisfiable rule with equality is equivalent to a rule without equality.<br />
No expressive power is gained if the query is satisfiable.</p>
<h2 id="query-composition-and-views"><a class="header" href="#query-composition-and-views">Query Composition and Views</a></h2>
<p>a <em>conjunctive query program</em> (with or without equality) is a sequence \(P\)
of rules having the form:
\[
\begin{split}
S_1(u_1) &amp; \leftarrow \text{body}_1 \\
S_2(u_2) &amp; \leftarrow \text{body}_2 \\
&amp; \vdots \\
S_m(u_m) &amp; \leftarrow \text{body}_m
\end{split}
\]
where</p>
<!-- prettier-ignore-start -->
<ul>
<li>each \(S_i\) is a distinct relation name not in \(\dbschema{R}\),</li>
<li>for each \(i \in [1, m]\), the only relation names that may occur in \(\body_i\) are in \(\dbschema{R} \cup \{ S_1, \ldots, S_{i-1} \}\).</li>
</ul>
<!-- prettier-ignore-end -->
<h3 id="closure-under-composition"><a class="header" href="#closure-under-composition">Closure under Composition</a></h3>
<p>If conjunctive query program \(P\) defines final relation \(S\),
then there is a conjunctive query \(q\),
possibly with equality,
such that on all input instances \(\dbinst{I}\),
\(q(\dbinst{I}) = P(\dbinst{I})(S)\).</p>
<p>If \(P\) is satisfiable, then there is a \(q\) without equality.</p>
<h3 id="composition-and-user-views"><a class="header" href="#composition-and-user-views">Composition and User Views</a></h3>
<p><em>views</em> are specified as queries (or query programs), which may be</p>
<ul>
<li><em>materialized</em>: a physical copy of the view is stored and maintained</li>
<li><em>virtual</em>: relevant information about the view is computed as needed
<ul>
<li>queries against the virtual view generate composed queries against the underlying database</li>
</ul>
</li>
</ul>
<h2 id="algebraic-perspectives"><a class="header" href="#algebraic-perspectives">Algebraic Perspectives</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h1 id="g1-pain-points"><a class="header" href="#g1-pain-points">G1 Pain Points</a></h1>
<h2 id="about-alcohol"><a class="header" href="#about-alcohol">About Alcohol</a></h2>
<ul>
<li>G1/G2: You must not drive if you have been drinking alcohol. Your blood-alcohol level must be zero.</li>
<li>All drivers who are 21 and under, regardless of license class, must have a BAC level of zero when operating a motor vehicle.</li>
<li>Blood-alcohol level &lt;0.05% is ok</li>
<li>0.05%-0.08% -&gt; warn range -&gt; not ok for warn-range suspension, not ok for accompanying driver.</li>
<li>&gt;0.08% is not ok</li>
</ul>
<h2 id="about-demerit-points"><a class="header" href="#about-demerit-points">About Demerit Points</a></h2>
<ul>
<li>New drivers: 9+ -&gt; suspended for 60d</li>
<li>Fully licensed drivers: 15 -&gt; suspended for 30d</li>
<li>7: Failing to remain at the scene of a collision, Failing to stop for police</li>
<li>6: careless, racing, exceeding the speed limit by 40+km/h if limit &lt;=80, or 50+km/h, failing to stop for a school bus.</li>
<li>5: only bus drivers</li>
<li>4: exceeding the speed limit by 30-49 km/h, following too closely, failing to stop at a pedestrian crossover.</li>
<li>3: exceeding the speed limit by 16-29 km/h, stop/yield sign, failing to report collision, wrong way (closed road/one-way road), emergency vehicles, HOV, opening a door, radar detector, crowded seat.</li>
<li>2: seatbelt, improper turn, lower headlight beam, sharing the road, signal, slow, towing, reversing on a highway</li>
</ul>
<h2 id="about-distance"><a class="header" href="#about-distance">About Distance</a></h2>
<h3 id="150m"><a class="header" href="#150m">150m</a></h3>
<ul>
<li>Headlights must shine a white light that can be seen at least 150 meters in front.</li>
<li>Red rear lights should be seen 150 meters away.</li>
<li>When you use high-beam headlights, remember to switch to low beams within 150 meters of an oncoming vehicle.</li>
<li>Never make a U-turn unless you can see at least 150 meters in both directions.</li>
<li>It is illegal to follow within 150 meters of a fire vehicle responding to an alarm.</li>
<li>Snow-removal vehicles on public roadways are equipped with flashing blue lights that can be seen from 150 meters.</li>
<li>Roadside stop: A 150-meter gap in both directions provides enough space to perform the move safely.</li>
</ul>
<h3 id="110m"><a class="header" href="#110m">110m</a></h3>
<ul>
<li>Headlights must shine a white light that is strong enough to light up objects 110 meters away.</li>
</ul>
<h3 id="100m"><a class="header" href="#100m">100m</a></h3>
<ul>
<li>Do not park on or within 100 meters of a bridge.</li>
</ul>
<h3 id="60m"><a class="header" href="#60m">60m</a></h3>
<ul>
<li>Use your low beams when you are less than 60 meters behind another vehicle unless you are passing it.</li>
</ul>
<h3 id="30m"><a class="header" href="#30m">30m</a></h3>
<ul>
<li>Passing within 30 meters of a pedestrian crossover is not permitted.</li>
<li>Passing left of a centerline is not permitted 30 meters from a bridge, viaduct or tunnel.</li>
</ul>
<h3 id="28m"><a class="header" href="#28m">28m</a></h3>
<ul>
<li>In fact, a recent study found that drivers who were texting or changing music on their phones traveled 28 meters further (nearly half a hockey rink) before responding to a hazard than drivers who were paying attention.</li>
</ul>
<h3 id="20m"><a class="header" href="#20m">20m</a></h3>
<ul>
<li>If you are coming from behind the bus, stop at least 20 meters away.</li>
</ul>
<h3 id="15m"><a class="header" href="#15m">15m</a></h3>
<ul>
<li>Do not park within 15 meters of the nearest rail of a level railway crossing.</li>
<li>Do not park within 15 meters if it is controlled by traffic lights.</li>
</ul>
<h3 id="9m"><a class="header" href="#9m">9m</a></h3>
<ul>
<li>Do not park within 9 meters of an intersection.</li>
</ul>
<h3 id="6m"><a class="header" href="#6m">6m</a></h3>
<ul>
<li>Do not park within six meters of a public entrance to a hotel, theatre or public hall when it is open to the public.</li>
</ul>
<h3 id="5m"><a class="header" href="#5m">5m</a></h3>
<ul>
<li>If a train is coming, stop at least 5 meters from the nearest rail or gate.</li>
</ul>
<h3 id="3m"><a class="header" href="#3m">3m</a></h3>
<ul>
<li>Do not park within 3 meters of a fire hydrant.</li>
</ul>
<h3 id="2m"><a class="header" href="#2m">2m</a></h3>
<ul>
<li>At streetcar stops, stay at least 2 meters behind the rear doors where passengers are getting off or on.</li>
</ul>
<h3 id="1m"><a class="header" href="#1m">1m</a></h3>
<ul>
<li>Bicycles and mopeds traveling at a lower speed than other traffic are expected to ride about 1 meter from the curb or parked cars.</li>
<li>When passing a cyclist, drivers of motor vehicles must maintain a minimum distance of 1 meter, where practical between their vehicle and the cyclist.</li>
<li>Drive alongside, or parallel to, the vehicle ahead of the empty space, leaving about 1 meter between the vehicles.</li>
</ul>
<h3 id="60cm"><a class="header" href="#60cm">60cm</a></h3>
<ul>
<li>Roadside stop: Leave at least 60 centimeters between your vehicle and the parked vehicle.</li>
</ul>
<h3 id="30cm"><a class="header" href="#30cm">30cm</a></h3>
<ul>
<li>Roadside stop: You should not be more than about 30 centimeters away from the curb or edge of the road.</li>
</ul>
<h2 id="other-numbers"><a class="header" href="#other-numbers">Other Numbers</a></h2>
<h3 id="10-times"><a class="header" href="#10-times">10 times</a></h3>
<ul>
<li>Texting or browsing on your phone takes your eyes off the road and increases your risk of crashing by 10 times.</li>
</ul>


                        <footer id="footer" style="margin-top: 8em;">
                        </footer>
                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <!-- Set the theme for giscus comments -->
        <script>
            function normGiscusTheme (theme) {
                if (theme == "light") {
                    return "light";
                } else if (theme == "rust") {
                    return "noborder_light";
                } else {
                    return "transparent_dark";
                }
            }

            function changeGiscusTheme (theme) {
                theme = normGiscusTheme(theme);

                function sendMessage(message) {
                    const iframe = document.querySelector('iframe.giscus-frame');
                    if (!iframe) return;
                    iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
                }

                sendMessage({
                    setConfig: {
                    theme: theme
                    }
                });
            }

            let giscusAttributes = {
                "src": "https://giscus.app/client.js",
                "data-repo": "xuhongxu96/xuhongxu96.github.io",
                "data-repo-id": "MDEwOlJlcG9zaXRvcnkxNDA0NTkxOTg=",
                "data-category": "Comments",
                "data-category-id": "DIC_kwDOCF88vs4CuW9z",
                "data-mapping": "og:title",
                "data-strict": "1",
                "data-reactions-enabled": "1",
                "data-emit-metadata": "0",
                "data-input-position": "bottom",
                "data-theme": normGiscusTheme(theme),
                "data-lang": "en",
                "data-loading": "lazy",
                "crossorigin": "anonymous",
                "async": "",
            };
            
            let giscusScript = document.createElement("script");
            Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
            document.getElementById("footer").appendChild(giscusScript);
        </script>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>


    </div>
    </body>
</html>
